{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x0IDQ2ZQMa4"
      },
      "source": [
        "### Model for 2 players only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "6EMTEY3DQRzr",
        "outputId": "d03ab600-a84e-466b-db56-da358d571e71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Checking folder: /content/drive/MyDrive/Colab Notebooks/DL2_model/2_games\n",
            "Found 3500 CSV files\n",
            "Combined DataFrame shape: (203568, 403)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   game_id  num_players  turn_number  current_player  gems_board_white  \\\n",
              "0        1            2            1               0                 4   \n",
              "1        1            2            1               1                 4   \n",
              "2        1            2            2               0                 3   \n",
              "3        1            2            2               1                 2   \n",
              "4        1            2            3               0                 1   \n",
              "\n",
              "   gems_board_blue  gems_board_green  gems_board_red  gems_board_black  \\\n",
              "0                4                 4               4                 4   \n",
              "1                4                 4               2                 4   \n",
              "2                3                 4               2                 3   \n",
              "3                2                 3               2                 3   \n",
              "4                1                 2               2                 3   \n",
              "\n",
              "   gems_board_gold  ...  gem_take2_green  gem_take2_red  gem_take2_black  \\\n",
              "0                5  ...              0.0            2.0              0.0   \n",
              "1                5  ...              NaN            NaN              NaN   \n",
              "2                5  ...              NaN            NaN              NaN   \n",
              "3                5  ...              NaN            NaN              NaN   \n",
              "4                5  ...              NaN            NaN              NaN   \n",
              "\n",
              "   noble_selection  gems_removed_white  gems_removed_blue  gems_removed_green  \\\n",
              "0               -1                   0                  0                   0   \n",
              "1               -1                   0                  0                   0   \n",
              "2               -1                   0                  0                   0   \n",
              "3               -1                   0                  0                   0   \n",
              "4               -1                   0                  0                   0   \n",
              "\n",
              "   gems_removed_red  gems_removed_black  gems_removed_gold  \n",
              "0                 0                   0                  0  \n",
              "1                 0                   0                  0  \n",
              "2                 0                   0                  0  \n",
              "3                 0                   0                  0  \n",
              "4                 0                   0                  0  \n",
              "\n",
              "[5 rows x 403 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2dad4a83-7b98-4947-a187-3e299c34cb2d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>game_id</th>\n",
              "      <th>num_players</th>\n",
              "      <th>turn_number</th>\n",
              "      <th>current_player</th>\n",
              "      <th>gems_board_white</th>\n",
              "      <th>gems_board_blue</th>\n",
              "      <th>gems_board_green</th>\n",
              "      <th>gems_board_red</th>\n",
              "      <th>gems_board_black</th>\n",
              "      <th>gems_board_gold</th>\n",
              "      <th>...</th>\n",
              "      <th>gem_take2_green</th>\n",
              "      <th>gem_take2_red</th>\n",
              "      <th>gem_take2_black</th>\n",
              "      <th>noble_selection</th>\n",
              "      <th>gems_removed_white</th>\n",
              "      <th>gems_removed_blue</th>\n",
              "      <th>gems_removed_green</th>\n",
              "      <th>gems_removed_red</th>\n",
              "      <th>gems_removed_black</th>\n",
              "      <th>gems_removed_gold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 403 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2dad4a83-7b98-4947-a187-3e299c34cb2d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2dad4a83-7b98-4947-a187-3e299c34cb2d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2dad4a83-7b98-4947-a187-3e299c34cb2d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-780b88a9-705c-4bea-a21c-06e5c46172f5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-780b88a9-705c-4bea-a21c-06e5c46172f5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-780b88a9-705c-4bea-a21c-06e5c46172f5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 1. Start by loading all the csv files of 2 players in a dataframe\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path structure in Google Drive\n",
        "games_folder = Path(\"/content/drive/MyDrive/Colab Notebooks/DL2_model/2_games\")\n",
        "\n",
        "print(\"Checking folder:\", games_folder)\n",
        "\n",
        "#Load the Files\n",
        "\n",
        "if not games_folder.exists():\n",
        "    print(\"Error: Folder does not exist.\")\n",
        "else:\n",
        "    csv_files = sorted(games_folder.glob(\"*.csv\"))\n",
        "    print(f\"Found {len(csv_files)} CSV files\")\n",
        "\n",
        "    if len(csv_files) == 0:\n",
        "        print(\"No csv files found in folder\")\n",
        "    else:\n",
        "        dfs = [pd.read_csv(file) for file in csv_files]\n",
        "        combined_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "        print(\"Combined DataFrame shape:\", combined_df.shape)\n",
        "        display(combined_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W43fJvmG5Au0"
      },
      "source": [
        "### 1. Feature engineering\n",
        "\n",
        "In Splendor, optimal decision-making requires understanding both the current game state and strategic relationships between resources cards, and opponents. The 285 engineered features capture three key dimensions: (1) observable game state (gems, visible cards, nobles), (2) player capabilities (resources, reductions, victory points), and (3) derived strategic signals (card affordability, proximity to nobles, relative advantages). By pre-computing these relationships and normalizing all values to [0,1], we simplify the learning task for our MLP baseline, allowing it to focus on pattern recognition rather than complex mathematical reasoning. This approach encodes domain expertise directly into the feature space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9Ry1HCABBj8H"
      },
      "outputs": [],
      "source": [
        "# Dictionary to store all normalized features\n",
        "normalized_features = {}\n",
        "\n",
        "#Copy of the combined dataframe\n",
        "df = combined_df.copy()\n",
        "features_df = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tw_eVCp1NFK5"
      },
      "outputs": [],
      "source": [
        "# 1. GLOBAL features for capturing temporal context and available resources on the board ==> 10 features\n",
        "\n",
        "# 1.1 Turn number for temporal context (early/mid/late game) ==> 1 feature\n",
        "normalized_features['turn_number'] = df[\"turn_number\"] / df['turn_number'].max()\n",
        "\n",
        "# 1.2. Gems on board for resource availability ==> 6 features\n",
        "for color in ['white', 'blue', 'green', 'red', 'black', 'gold']:\n",
        "    normalized_features[f'gems_board_{color}'] = df[f'gems_board_{color}'] / df[f'gems_board_{color}'].max()\n",
        "\n",
        "# 1.3. Normalize for remaining cards on deck\n",
        "# Helps to learn about the progress of the game and time the strategies ==> 3 features\n",
        "normalized_features['deck_level1_remaining'] = df['deck_level1_remaining'] / df['deck_level1_remaining'].max()\n",
        "normalized_features['deck_level2_remaining'] = df['deck_level2_remaining'] / df['deck_level2_remaining'].max()\n",
        "normalized_features['deck_level3_remaining'] = df['deck_level3_remaining'] / df['deck_level3_remaining'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "04fDIvpENO4O"
      },
      "outputs": [],
      "source": [
        "# 2. VISIBLE CARDS ==> 12 cards x 7 features (each color) = 84 features\n",
        "# Cards on the board represent immediate purchasing opportunities\n",
        "\n",
        "# 2.1. Normalize for victory points and cost for each color\n",
        "# The maximum for vp across all card is 5\n",
        "# There are 12 cards in total\n",
        "\n",
        "for i in range(12):\n",
        "  normalized_features[f'card{i}_vp'] = df[f'card{i}_vp'] / 5.0\n",
        "  normalized_features[f'card{i}_level'] = df[f'card{i}_level'] / 3.0 # Level (ordinal: 1, 2, 3 → represents difficulty/tier)\n",
        "  for color in ['white', 'blue', 'green', 'red', 'black']:\n",
        "    normalized_features[f'card{i}_cost_{color}'] = df[f'card{i}_cost_{color}'] / df[f'card{i}_cost_{color}'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "02c9lyT2NVJj"
      },
      "outputs": [],
      "source": [
        "#3. NOBLES ==> 5 nobles x 6 features = 30 features\n",
        "# Represent long-term strategic objectives\n",
        "for i in range(5):\n",
        "    # VP (always 3, but normalized for consistency)\n",
        "    normalized_features[f'noble{i}_vp'] = df[f'noble{i}_vp'] / 3.0\n",
        "\n",
        "    # Requirements (reduction bonuses needed)\n",
        "    for color in ['white', 'blue', 'green', 'red', 'black']:\n",
        "        normalized_features[f'noble{i}_req_{color}'] = df[f'noble{i}_req_{color}'] / df[f'noble{i}_req_{color}'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aMqAUOItNY9F"
      },
      "outputs": [],
      "source": [
        "# 4. PLAYER STATES (2 players × 42 features = 84 features)\n",
        "# Captures resources, reductions, VP, and reserved cards for both players\n",
        "for player_idx in range(2):\n",
        "    # 4.1. Gems (immediate purchasing power)\n",
        "    for color in ['white', 'blue', 'green', 'red', 'black', 'gold']:\n",
        "        normalized_features[f'player{player_idx}_gems_{color}'] = df[f'player{player_idx}_gems_{color}'] / df[f'player{player_idx}_gems_{color}'].max()\n",
        "\n",
        "    # 4.2. Permanent reductions (the \"engine\" - permanent discounts)\n",
        "    for color in ['white', 'blue', 'green', 'red', 'black']:\n",
        "        normalized_features[f'player{player_idx}_reduction_{color}'] = df[f'player{player_idx}_reduction_{color}'] / df[f'player{player_idx}_reduction_{color}'].max()\n",
        "\n",
        "    # 4.3. Victory points (goal is 15)\n",
        "    normalized_features[f'player{player_idx}_vp'] = df[f'player{player_idx}_vp'] / df[f'player{player_idx}_vp'].max()\n",
        "\n",
        "    # 4.4. Position (0 or 1 - already binary)\n",
        "    normalized_features[f'player{player_idx}_position'] = df[f'player{player_idx}_position']\n",
        "\n",
        "    # 4.5. Reserved cards (hidden strategic advantage - max 3 per player)\n",
        "    for reserve_idx in range(3):\n",
        "        normalized_features[f'player{player_idx}_reserved{reserve_idx}_vp'] = df[f'player{player_idx}_reserved{reserve_idx}_vp'] / df[f'player{player_idx}_reserved{reserve_idx}_vp'].max()\n",
        "        normalized_features[f'player{player_idx}_reserved{reserve_idx}_level'] = df[f'player{player_idx}_reserved{reserve_idx}_level'] / 3.0\n",
        "\n",
        "        for color in ['white', 'blue', 'green', 'red', 'black']:\n",
        "            normalized_features[f'player{player_idx}_reserved{reserve_idx}_cost_{color}'] = df[f'player{player_idx}_reserved{reserve_idx}_cost_{color}'] / df[f'player{player_idx}_reserved{reserve_idx}_cost_{color}'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Cs5TfTy5Neot"
      },
      "outputs": [],
      "source": [
        "# 5. DERIVED STRATEGIC FEATURES\n",
        "# Pre-computed relationships that help the MLP understand strategic situations\n",
        "import numpy as np\n",
        "\n",
        "#5.1 Affordability\n",
        "# Question: \"Can the active player buy this card RIGHT NOW with current resources?\"\n",
        "# Logic: For each card, check if (gems + reductions + gold) >= card cost\n",
        "\n",
        "# extract current_player for fast indexing\n",
        "current_player = df['current_player'].values\n",
        "\n",
        "# Loop through each of the 12 visible cards\n",
        "for card_idx in range(12):\n",
        "\n",
        "    #1.Calculate total gold needed for PLAYER 0 to buy this card\n",
        "    total_gold_p0 = np.zeros(len(df))  # Start with 0 gold needed per row\n",
        "\n",
        "    for color in ['white', 'blue', 'green', 'red', 'black']:\n",
        "        # Get card cost for this color (same for all rows)\n",
        "        cost = df[f'card{card_idx}_cost_{color}'].values\n",
        "\n",
        "        # Calculate what player 0 has available = gems + permanent reductions\n",
        "        available_p0 = (df[f'player0_gems_{color}'].values +\n",
        "                       df[f'player0_reduction_{color}'].values)\n",
        "\n",
        "        # Calculate : how much is missing? (0 if already enough)\n",
        "        shortfall_p0 = np.maximum(0, cost - available_p0)\n",
        "\n",
        "        # Accumulate shortfall across all 5 colors\n",
        "        total_gold_p0 += shortfall_p0\n",
        "\n",
        "    # Check if player 0 has enough gold to cover all shortfalls\n",
        "    can_afford_p0 = (total_gold_p0 <= df['player0_gems_gold'].values).astype(float)\n",
        "\n",
        "    #Same logic for the other player\n",
        "\n",
        "    # 2. Calculate total gold needed for PLAYER 1 to buy this card\n",
        "    total_gold_p1 = np.zeros(len(df))  # Start with 0 gold needed per row\n",
        "\n",
        "    for color in ['white', 'blue', 'green', 'red', 'black']:\n",
        "        # Get card cost for this color\n",
        "        cost = df[f'card{card_idx}_cost_{color}'].values\n",
        "\n",
        "        # Calculate what player 1 has available\n",
        "        available_p1 = (df[f'player1_gems_{color}'].values +\n",
        "                       df[f'player1_reduction_{color}'].values)\n",
        "\n",
        "        # Calculate shortfall for player 1\n",
        "        shortfall_p1 = np.maximum(0, cost - available_p1)\n",
        "\n",
        "        # Accumulate shortfall across all 5 colors\n",
        "        total_gold_p1 += shortfall_p1\n",
        "\n",
        "    # Check if player 1 has enough gold to cover all shortfalls\n",
        "    can_afford_p1 = (total_gold_p1 <= df['player1_gems_gold'].values).astype(float)\n",
        "\n",
        "\n",
        "    # 3. Select the right affordability based on whose turn it is\n",
        "    # For each row: if current_player=0, use can_afford_p0, else use can_afford_p1\n",
        "    normalized_features[f'can_afford_card{card_idx}'] = np.where(\n",
        "        current_player == 0,  # Condition: is it player 0's turn?\n",
        "        can_afford_p0,        # If yes, use player 0's affordability\n",
        "        can_afford_p1         # If no, use player 1's affordability\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "N4mTaHRTSKIZ"
      },
      "outputs": [],
      "source": [
        "# 5.2 Distances to Nobles (25 features: 5 nobles × 5 colors)\n",
        "# How many more reductions needed to attract each noble?\n",
        "\n",
        "current_player = df['current_player'].values\n",
        "\n",
        "# Loop through each of the 5 nobles\n",
        "for noble_idx in range(5):\n",
        "\n",
        "    # Loop through each color requirement\n",
        "    for color in ['white', 'blue', 'green', 'red', 'black']:\n",
        "\n",
        "        # 1.Get noble requirement for this color (same across all rows)\n",
        "        required = df[f'noble{noble_idx}_req_{color}'].values\n",
        "\n",
        "        # 2.Get reductions owned by each player\n",
        "        owned_p0 = df[f'player0_reduction_{color}'].values\n",
        "        owned_p1 = df[f'player1_reduction_{color}'].values\n",
        "\n",
        "        # 3.Calculate distance for each player\n",
        "        # Distance = how many more reductions needed (0 if already satisfied)\n",
        "        distance_p0 = np.maximum(0, required - owned_p0)\n",
        "        distance_p1 = np.maximum(0, required - owned_p1)\n",
        "\n",
        "        # 4.Select based on whose turn it is\n",
        "        # For each row: if current_player=0, use distance_p0, else use distance_p1\n",
        "        distance_active = np.where(\n",
        "            current_player == 0,  # Condition: is it player 0's turn?\n",
        "            distance_p0,          # If yes, use player 0's distance\n",
        "            distance_p1           # If no, use player 1's distance\n",
        "        )\n",
        "\n",
        "        # 5.Normalize by max requirement (4)\n",
        "        normalized_features[f'distance_noble{noble_idx}_{color}'] = distance_active / 4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cnYl-hUaTB5J"
      },
      "outputs": [],
      "source": [
        "# 5.3 Relative advantages\n",
        "# Compare active player vs opponent on some key metrics\n",
        "# Relative VP\n",
        "\n",
        "# Pre-extract current_player as numpy array for fast indexing\n",
        "current_player = df['current_player'].values\n",
        "\n",
        "# --- F3.1: RELATIVE VICTORY POINTS ---\n",
        "# Who is winning? Positive = active player ahead, Negative = opponent ahead\n",
        "vp_p0 = df['player0_vp'].values\n",
        "vp_p1 = df['player1_vp'].values\n",
        "\n",
        "# Calculate difference: active player VP - opponent VP\n",
        "relative_vp = np.where(\n",
        "    current_player == 0,     # If player 0's turn\n",
        "    vp_p0 - vp_p1,          # Player 0 - Player 1\n",
        "    vp_p1 - vp_p0           # Player 1 - Player 0\n",
        ")\n",
        "normalized_features['relative_vp'] = relative_vp / 15.0  # Normalize by winning VP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tlHh1ZoSTMW_"
      },
      "outputs": [],
      "source": [
        "# 5.4 RELATIVE GEMS (5 colors)\n",
        "# Who has more gems of each color?\n",
        "for color in ['white', 'blue', 'green', 'red', 'black']:\n",
        "    gems_p0 = df[f'player0_gems_{color}'].values\n",
        "    gems_p1 = df[f'player1_gems_{color}'].values\n",
        "\n",
        "    # Calculate difference: active player gems - opponent gems\n",
        "    relative_gems = np.where(\n",
        "        current_player == 0,     # If player 0's turn\n",
        "        gems_p0 - gems_p1,      # Player 0 - Player 1\n",
        "        gems_p1 - gems_p0       # Player 1 - Player 0\n",
        "    )\n",
        "    normalized_features[f'relative_gems_{color}'] = relative_gems / relative_gems.max() # Normalize by max gems\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kL1E66AWTT-D"
      },
      "outputs": [],
      "source": [
        "# 5.5 RELATIVE REDUCTIONS (5 colors) ---\n",
        "# Who has a stronger \"engine\" (more permanent bonuses)?\n",
        "for color in ['white', 'blue', 'green', 'red', 'black']:\n",
        "    reduction_p0 = df[f'player0_reduction_{color}'].values\n",
        "    reduction_p1 = df[f'player1_reduction_{color}'].values\n",
        "\n",
        "    # Calculate difference: active player reductions - opponent reductions\n",
        "    relative_reductions = np.where(\n",
        "        current_player == 0,     # If player 0's turn\n",
        "        reduction_p0 - reduction_p1,  # Player 0 - Player 1\n",
        "        reduction_p1 - reduction_p0   # Player 1 - Player 0\n",
        "    )\n",
        "    normalized_features[f'relative_reduction_{color}'] = relative_reductions / relative_reductions.max() # Normalize by typical max\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iqFNO-kfTdDz"
      },
      "outputs": [],
      "source": [
        "# 5.6 GEM DIVERSITY\n",
        "# How many different gem colors does the active player have?\n",
        "# Get gems for each player and color\n",
        "gems_p0_white = df['player0_gems_white'].values\n",
        "gems_p0_blue = df['player0_gems_blue'].values\n",
        "gems_p0_green = df['player0_gems_green'].values\n",
        "gems_p0_red = df['player0_gems_red'].values\n",
        "gems_p0_black = df['player0_gems_black'].values\n",
        "\n",
        "gems_p1_white = df['player1_gems_white'].values\n",
        "gems_p1_blue = df['player1_gems_blue'].values\n",
        "gems_p1_green = df['player1_gems_green'].values\n",
        "gems_p1_red = df['player1_gems_red'].values\n",
        "gems_p1_black = df['player1_gems_black'].values\n",
        "\n",
        "# Count how many colors each player has (binary: has gems or not)\n",
        "diversity_p0 = ((gems_p0_white > 0).astype(int) +\n",
        "                (gems_p0_blue > 0).astype(int) +\n",
        "                (gems_p0_green > 0).astype(int) +\n",
        "                (gems_p0_red > 0).astype(int) +\n",
        "                (gems_p0_black > 0).astype(int))\n",
        "\n",
        "diversity_p1 = ((gems_p1_white > 0).astype(int) +\n",
        "                (gems_p1_blue > 0).astype(int) +\n",
        "                (gems_p1_green > 0).astype(int) +\n",
        "                (gems_p1_red > 0).astype(int) +\n",
        "                (gems_p1_black > 0).astype(int))\n",
        "\n",
        "# Select based on current player and normalize by max (5 colors)\n",
        "gem_diversity = np.where(\n",
        "    current_player == 0,\n",
        "    diversity_p0,\n",
        "    diversity_p1\n",
        ") / 5.0\n",
        "\n",
        "normalized_features['gem_diversity'] = gem_diversity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9Ho7h8WKTdzZ"
      },
      "outputs": [],
      "source": [
        "# 5.7 Total gems\n",
        "# How many total gems does the active player have? (approaching 10 = must buy/reserve soon)\n",
        "total_gems_p0 = (gems_p0_white + gems_p0_blue + gems_p0_green +\n",
        "                 gems_p0_red + gems_p0_black + df['player0_gems_gold'].values)\n",
        "\n",
        "total_gems_p1 = (gems_p1_white + gems_p1_blue + gems_p1_green +\n",
        "                 gems_p1_red + gems_p1_black + df['player1_gems_gold'].values)\n",
        "\n",
        "# Select based on current player and normalize by max (10 gems)\n",
        "total_gems = np.where(\n",
        "    current_player == 0,\n",
        "    total_gems_p0,\n",
        "    total_gems_p1\n",
        ") / 10.0\n",
        "\n",
        "normalized_features['total_gems'] = total_gems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xpejaRN0TjOZ"
      },
      "outputs": [],
      "source": [
        "# 5.8 Total reduction\n",
        "# How powerful is the active player (more reductions = easier to buy cards)\n",
        "total_reductions_p0 = (df['player0_reduction_white'].values +\n",
        "                       df['player0_reduction_blue'].values +\n",
        "                       df['player0_reduction_green'].values +\n",
        "                       df['player0_reduction_red'].values +\n",
        "                       df['player0_reduction_black'].values)\n",
        "\n",
        "total_reductions_p1 = (df['player1_reduction_white'].values +\n",
        "                       df['player1_reduction_blue'].values +\n",
        "                       df['player1_reduction_green'].values +\n",
        "                       df['player1_reduction_red'].values +\n",
        "                       df['player1_reduction_black'].values)\n",
        "\n",
        "# Select based on current player and normalize by theoretical max of 35\n",
        "total_reductions = np.where(\n",
        "    current_player == 0,\n",
        "    total_reductions_p0,\n",
        "    total_reductions_p1\n",
        ") / 24.0\n",
        "\n",
        "normalized_features['total_reductions'] = total_reductions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ibwiZ_lvLwKZ"
      },
      "outputs": [],
      "source": [
        "#6. Concatenate all features to avoid fragmentation of dataframe\n",
        "# From dictionary to dataframe\n",
        "\n",
        "features_df = pd.DataFrame(normalized_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZW12p8N-b2eu"
      },
      "outputs": [],
      "source": [
        "# Remove redundant player0_position and player1_position from the dataframe\n",
        "cols_to_remove = [\"player0_position\", \"player1_position\"]\n",
        "features_df = features_df.drop(columns=cols_to_remove)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-5fvSJW7cwnb"
      },
      "outputs": [],
      "source": [
        "# Download first 57 rows as CSV to make some manual spotchecks\n",
        "# features_df.head(57).to_csv('first_57_rows2.csv', index=False)\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download('first_57_rows2.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH7IXBmddcF6"
      },
      "source": [
        "#### 2. Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rpeo2Z6vdbRv"
      },
      "outputs": [],
      "source": [
        "# 2.1 Delete the empty columns in the features_df\n",
        "features_df = features_df.dropna(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRuZfeM0dtsb",
        "outputId": "52c32fe8-2a28-4ea7-edea-b2c1445fc4aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features: 144\n"
          ]
        }
      ],
      "source": [
        "# 2.2 Find the final number of features\n",
        "nb_features = features_df.columns.size\n",
        "print(\"Number of features:\", nb_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1NXPza4UeDrT"
      },
      "outputs": [],
      "source": [
        "# 2.3 Define the Target Variable (Y): Extract the action the current player took (the label your model will try to predict) from the original combined DataFrame.\n",
        "# Y is action_type in the df\n",
        "Y = df[\"action_type\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPB5e9VggFrg",
        "outputId": "9d485076-d865-4132-b00a-668b25484f42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in feature dataframe: 203568\n",
            "Number of columns in feature dataframe: 144\n",
            "\n",
            "\n",
            "Number of rows in the target column: 203568\n"
          ]
        }
      ],
      "source": [
        "# 2.4 Print shape of target column and feature dataframe\n",
        "rows, cols = features_df.shape\n",
        "\n",
        "print(\"Number of rows in feature dataframe:\", rows)\n",
        "print(\"Number of columns in feature dataframe:\", cols)\n",
        "print('\\n')\n",
        "print(\"Number of rows in the target column:\", Y.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "MjPGzV0GgX_P"
      },
      "outputs": [],
      "source": [
        "# 2.5 Combine the target column with the feature dataframe\n",
        "Y = Y.rename(\"target\")\n",
        "final_df = pd.concat([features_df, Y], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFJHIReIjv6X"
      },
      "source": [
        "#### 3. Split the dataset into train and test dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jwPs91Uj1Si",
        "outputId": "94ed938c-4772-4766-a0ae-c9cc03280b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape: (142497, 144) (142497,)\n",
            "Validation set shape: (30535, 144) (30535,)\n",
            "Test set shape: (30536, 144) (30536,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Separate features (X) and target (y)\n",
        "X = final_df.drop(columns=[\"target\"])\n",
        "y = final_df[\"target\"]\n",
        "\n",
        "# 2. First split: 70% train, 30% temp (which will become 15% val + 15% test)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3,           # 30% for temp (val + test)\n",
        "    random_state=42,         # reproducibility\n",
        "    stratify=y               # keeps class distribution balanced\n",
        ")\n",
        "\n",
        "# 3. Second split: split the 30% temp into 15% val and 15% test (50-50 split of temp)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp,\n",
        "    test_size=0.5,           # 50% of temp = 15% of total\n",
        "    random_state=42,         # reproducibility\n",
        "    stratify=y_temp          # keeps class distribution balanced\n",
        ")\n",
        "\n",
        "print(\"Train set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
        "print(\"Test set shape:\", X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idPH6HLtkPl6",
        "outputId": "8631db39-acf6-484b-c043-754b8181fd5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset size: 203568 rows\n",
            "----------------------------------------\n",
            "Training features (X_train) size:   (142497, 144)\n",
            "Validation features (X_val) size:  (30535, 144)\n",
            "Testing features (X_test) size:    (30536, 144)\n",
            "----------------------------------------\n",
            "Training target (y_train) size:    (142497,)\n",
            "Validation target (y_val) size:   (30535,)\n",
            "Testing target (y_test) size:     (30536,)\n",
            "\n",
            "Class distribution in y_train:\n",
            "target\n",
            "build            0.518193\n",
            "take 3 tokens    0.454838\n",
            "take 2 tokens    0.026176\n",
            "reserve          0.000793\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Class distribution in y_val:\n",
            "target\n",
            "build            0.518192\n",
            "take 3 tokens    0.454855\n",
            "take 2 tokens    0.026167\n",
            "reserve          0.000786\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Class distribution in y_test:\n",
            "target\n",
            "build            0.518208\n",
            "take 3 tokens    0.454840\n",
            "take 2 tokens    0.026166\n",
            "reserve          0.000786\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# 3. Print the resulting sizes to verify the split\n",
        "print(f\"Original dataset size: {len(X)} rows\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"Training features (X_train) size:   {X_train.shape}\")\n",
        "print(f\"Validation features (X_val) size:  {X_val.shape}\")\n",
        "print(f\"Testing features (X_test) size:    {X_test.shape}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"Training target (y_train) size:    {y_train.shape}\")\n",
        "print(f\"Validation target (y_val) size:   {y_val.shape}\")\n",
        "print(f\"Testing target (y_test) size:     {y_test.shape}\")\n",
        "\n",
        "# 4. Verify the class balance\n",
        "print(\"\\nClass distribution in y_train:\")\n",
        "print(y_train.value_counts(normalize=True))\n",
        "\n",
        "print(\"\\nClass distribution in y_val:\")\n",
        "print(y_val.value_counts(normalize=True))\n",
        "\n",
        "print(\"\\nClass distribution in y_test:\")\n",
        "print(y_test.value_counts(normalize=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZVIgDwAIY9T"
      },
      "source": [
        "#### 4. Address class imbalance\n",
        ">With reserve at only 0.08%, use class weights in your loss function (inversely proportional to class frequencies) to prevent the model from ignoring this rare but strategically important action."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsh0YaRzLbHY"
      },
      "source": [
        "### 5 . Training the MLP model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sRmhEPCuLiS8"
      },
      "outputs": [],
      "source": [
        "# Importing the right libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# 1. Convert to PyTorch tensors\n",
        "# Convert features\n",
        "X_train_tensor = torch.FloatTensor(X_train.values)\n",
        "X_val_tensor   = torch.FloatTensor(X_val.values)\n",
        "X_test_tensor  = torch.FloatTensor(X_test.values)\n",
        "\n",
        "# Convert target\n",
        "# Convert target labels (strings) to class indices\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_indices = label_encoder.fit_transform(y_train)   # Fit on train\n",
        "y_val_indices   = label_encoder.transform(y_val)         # Transform validation\n",
        "y_test_indices  = label_encoder.transform(y_test)        # Transform test\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "y_train_tensor = torch.LongTensor(y_train_indices)\n",
        "y_val_tensor   = torch.LongTensor(y_val_indices)\n",
        "y_test_tensor  = torch.LongTensor(y_test_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrdjnU_XMK-0",
        "outputId": "5b89d90e-2389-41cf-9fc3-0c8b32d36c4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label encoding:\n",
            "  0: build\n",
            "  1: reserve\n",
            "  2: take 2 tokens\n",
            "  3: take 3 tokens\n"
          ]
        }
      ],
      "source": [
        "# 1.1 Verify encoding\n",
        "print(\"Label encoding:\")\n",
        "for idx, label in enumerate(label_encoder.classes_):\n",
        "    print(f\"  {idx}: {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dgHPfcaVNq1j"
      },
      "outputs": [],
      "source": [
        "# 2. Create TensorDatasets\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset   = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "test_dataset  = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# 3. Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPX19inFNyf4",
        "outputId": "fc664753-d539-4b0b-d2f3-1fae23f6e4db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights:\n",
            "  build: 0.48\n",
            "  reserve: 315.26\n",
            "  take 2 tokens: 9.55\n",
            "  take 3 tokens: 0.55\n"
          ]
        }
      ],
      "source": [
        "# 3. Compute the class weights (for imbalanced classes)\n",
        "# This time we do it before training with the right label encoding\n",
        "\n",
        "# Label encoding:\n",
        "#   0: build\n",
        "#   1: reserve\n",
        "#   2: take 2 tokens\n",
        "#   3: take 3 tokens\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "classes = np.array([0, 1, 2, 3])\n",
        "\n",
        "# Compute weights based on training set only\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=classes,\n",
        "    y=y_train_indices\n",
        ")\n",
        "class_weights_tensor = torch.FloatTensor(class_weights)\n",
        "\n",
        "print(\"Class weights:\")\n",
        "class_names = ['build', 'reserve', 'take 2 tokens', 'take 3 tokens']\n",
        "for cls_name, weight in zip(class_names, class_weights):\n",
        "    print(f\"  {cls_name}: {weight:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "HVXgsA-6Oxp9"
      },
      "outputs": [],
      "source": [
        "# 4. Define the MLP Model\n",
        "\n",
        "class SplendorMLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden1, hidden2, num_classes, dropout):\n",
        "        super(SplendorMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden1)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden1)\n",
        "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden2)\n",
        "        self.fc3 = nn.Linear(hidden2, num_classes)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)  # No softmax here - CrossEntropyLoss handles it\n",
        "        return x\n",
        "\n",
        "# Instantiate model\n",
        "model = SplendorMLP(input_dim=144, hidden1=256, hidden2=128, num_classes=4, dropout=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "dOFXFTIIO0Yx"
      },
      "outputs": [],
      "source": [
        "#5. Define the loss, the optimizr and the scheduler\n",
        "\n",
        "# CrossEntropyLoss is used for multi-class classification.\n",
        "# The 'weight' argument lets us handle class imbalance by giving rare classes more importance.\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n",
        "# Adam optimizer is chosen for its adaptive learning rate and efficiency.\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Scheduler automatically reduces the learning rate when validation loss stops improving.\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku6gzWTvPMIV",
        "outputId": "58e4d38a-250a-4a4e-b499-19238f409d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training...\n",
            "================================================================================\n",
            "Epoch [10/100]\n",
            "  Train Loss: 0.6718, Train Acc: 63.78%\n",
            "  Val Loss:   0.6845, Val Acc:   65.79%\n",
            "Epoch [20/100]\n",
            "  Train Loss: 0.5931, Train Acc: 67.15%\n",
            "  Val Loss:   0.7293, Val Acc:   66.84%\n",
            "\n",
            "Early stopping triggered at epoch 27\n",
            "\n",
            "================================================================================\n",
            "Training complete!\n",
            "Best validation loss: 0.6708\n"
          ]
        }
      ],
      "source": [
        "#6. Training loop (First attempt, no GPU)\n",
        "\n",
        "num_epochs = 100\n",
        "best_val_loss = float('inf') # Track best validation loss\n",
        "patience_counter = 0\n",
        "early_stop_patience = 15\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader: # Iterate through mini-batches of data\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch) # Get model predictions (logits) for this batch\n",
        "        loss = criterion(outputs, y_batch) # Calculate loss between predictions and true labels\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad() # Clear gradients from previous iteration (prevents accumulation)\n",
        "        loss.backward() # Compute gradients via backpropagation\n",
        "        optimizer.step() # Update model weights using computed gradients\n",
        "\n",
        "        # Track metrics\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        train_total += y_batch.size(0)\n",
        "        train_correct += (predicted == y_batch).sum().item() # Count correct predictions\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    train_accuracy = 100 * train_correct / train_total\n",
        "\n",
        "    #==============================================================================\n",
        "    # Validation phase\n",
        "    model.eval() # Set model to evaluation mode (disables dropout, fixes batchnorm)\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad(): # Disable gradient computation (saves memory and speeds up inference)\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_total += y_batch.size(0)\n",
        "            val_correct  += (predicted == y_batch).sum().item() # Count correct predictions\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler.step(avg_val_loss) # Reduce learning rate if valid loss plateaus\n",
        "\n",
        "   # -------------------\n",
        "    # Print progress\n",
        "    # -------------------\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "        print(f\"  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}%\")\n",
        "        print(f\"  Val Loss:   {avg_val_loss:.4f}, Val Acc:   {val_accuracy:.2f}%\")\n",
        "\n",
        "    # -------------------\n",
        "    # Early stopping based on validation loss\n",
        "    # -------------------\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), 'best_splendor_model.pth')  # Save best model\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= early_stop_patience:\n",
        "        print(f\"\\nEarly stopping triggered at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Training complete!\")\n",
        "print(f\"Best validation loss: {best_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLrRpZfFViv7",
        "outputId": "fb8b6804-3d88-4969-b32d-2c064b03f98c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "CLASSIFICATION REPORT\n",
            "================================================================================\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        build       0.77      0.70      0.73     15824\n",
            "      reserve       0.04      0.83      0.08        24\n",
            "take 2 tokens       0.11      0.83      0.20       799\n",
            "take 3 tokens       0.75      0.54      0.63     13889\n",
            "\n",
            "     accuracy                           0.63     30536\n",
            "    macro avg       0.42      0.73      0.41     30536\n",
            " weighted avg       0.75      0.63      0.67     30536\n",
            "\n",
            "\n",
            "================================================================================\n",
            "CONFUSION MATRIX\n",
            "================================================================================\n",
            "               build  reserve  take 2 tokens  take 3 tokens\n",
            "build          11038      359           2041           2386\n",
            "reserve            4       20              0              0\n",
            "take 2 tokens     52        0            667             80\n",
            "take 3 tokens   3164      121           3111           7493\n",
            "\n",
            "================================================================================\n",
            "PREDICTION vs ACTUAL DISTRIBUTION\n",
            "================================================================================\n",
            "build                - Predicted: 14258, Actual: 15824\n",
            "reserve              - Predicted:   500, Actual:    24\n",
            "take 2 tokens        - Predicted:  5819, Actual:   799\n",
            "take 3 tokens        - Predicted:  9959, Actual: 13889\n"
          ]
        }
      ],
      "source": [
        "# # Final Test Evaluation - no GPU\n",
        "# PER-CLASS METRICS\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Get predictions\n",
        "model.load_state_dict(torch.load('best_splendor_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "all_predictions = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        outputs = model(X_batch)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_predictions.extend(predicted.numpy())\n",
        "        all_targets.extend(y_batch.numpy())\n",
        "\n",
        "all_predictions = np.array(all_predictions)\n",
        "all_targets = np.array(all_targets)\n",
        "\n",
        "# Get class names\n",
        "class_names = label_encoder.classes_\n",
        "\n",
        "# Print classification report\n",
        "print(\"=\"*80)\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(\"=\"*80)\n",
        "print(classification_report(all_targets, all_predictions, target_names=class_names))\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CONFUSION MATRIX\")\n",
        "print(\"=\"*80)\n",
        "cm = confusion_matrix(all_targets, all_predictions)\n",
        "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "print(cm_df)\n",
        "\n",
        "# Check prediction distribution\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PREDICTION vs ACTUAL DISTRIBUTION\")\n",
        "print(\"=\"*80)\n",
        "for i, cls_name in enumerate(class_names):\n",
        "    pred_count = (all_predictions == i).sum()\n",
        "    actual_count = (all_targets == i).sum()\n",
        "    print(f\"{cls_name:20s} - Predicted: {pred_count:5d}, Actual: {actual_count:5d}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Architecture 1: 256 → 128 → 4, dropout 0.3\n",
        "Accuracy: 63%\n",
        "\n",
        "Macro F1: 0.41 (weighted F1: 0.67)\n",
        "\n",
        "Strengths:\n",
        "\n",
        "Good performance on majority classes (build and take 3 tokens).\n",
        "\n",
        "Recall for rare classes (reserve, take 2 tokens) is surprisingly high (0.83), meaning the model often flags them.\n",
        "\n",
        "Weaknesses:\n",
        "\n",
        "Precision for rare classes is extremely low (0.04 and 0.11), leading to floods of false positives.\n",
        "\n",
        "Over-prediction: e.g., reserve predicted 500 times vs only 24 actual.\n",
        "\n",
        "Interpretation: The larger model memorizes patterns and aggressively predicts minority classes, but without precision. Accuracy looks decent because majority classes dominate."
      ],
      "metadata": {
        "id": "vgC9kbePNgJm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiL-GTXeZ40J"
      },
      "source": [
        "The model achieves 63% accuracy but this metric is misleading due to severe class imbalance issues. While it handles the dominant \"build\" and \"take 3 tokens\" classes reasonably well (77% and 75% precision), it catastrophically fails on minority classes.\n",
        "\n",
        "The most critical failure is \"reserve\" (0.08% of data), which the model over-predicts by 21× (500 predictions vs 24 actual), achieving only 4% precision despite 83% recall. Similarly, \"take 2 tokens\" is over-predicted by 7.3× (5,819 vs 799 actual) with just 11% precision. These extreme over-predictions create floods of false positives that would make the model unusable in practice.\n",
        "\n",
        "The confusion matrix shows systematic errors: 3,164 \"take 3 tokens\" misclassified as \"build\" and 3,111 as \"take 2 tokens.\" The model is simultaneously biased toward common classes when uncertain, yet over-triggers on rare classes. The gap between macro F1 (0.41) and weighted F1 (0.67) confirms that minority class failures are masked by dominant class performance, making the 63% accuracy fundamentally unreliable as a quality metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ67iTIEaa0D"
      },
      "source": [
        "#7. Training loop with MLP (Second attempt)`\n",
        "\n",
        "Key Changes:\n",
        "\n",
        "1. Capped weights to 10.0 - prevents \"reserve\" (315→10) from dominating\n",
        "2. Smaller model (256→256 becomes 128→64) - less overfitting\n",
        "3. Higher dropout (0.3→0.4) - better generalization\n",
        "4. L2 regularization - penalizes large weights\n",
        "5. F1-score for early stopping - better metric for imbalanced data\n",
        "6. Better monitoring - shows F1-score during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ_yAHtmjrBe",
        "outputId": "ff2dc358-3c77-4461-8b3c-c9060f8a1c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: Tesla T4\n",
            "GPU Memory: 15.83 GB\n"
          ]
        }
      ],
      "source": [
        "# Check and set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imFj5mAqbIYq",
        "outputId": "f595dbcb-e02d-4712-bc33-93b2a1b26e37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original vs Capped Class Weights:\n",
            "  build               :    0.48 ->  0.50\n",
            "  reserve             :  315.26 -> 10.00\n",
            "  take 2 tokens       :    9.55 ->  9.55\n",
            "  take 3 tokens       :    0.55 ->  0.55\n"
          ]
        }
      ],
      "source": [
        "# 1. COMPUTE CLASS WEIGHTS - WITH CAPPING TO PREVENT EXTREMES\n",
        "\n",
        "classes = np.array([0, 1, 2, 3])\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=classes,\n",
        "    y=y_train_indices\n",
        ")\n",
        "\n",
        "# CAP THE WEIGHTS: Prevent extreme values from dominating\n",
        "class_weights_capped = np.clip(class_weights, 0.5, 10.0)\n",
        "\n",
        "class_weights_tensor = torch.FloatTensor(class_weights_capped)\n",
        "\n",
        "# Move class weights to GPU (for criterion)\n",
        "class_weights_tensor = class_weights_tensor.to(device)\n",
        "\n",
        "print(\"Original vs Capped Class Weights:\")\n",
        "class_names = label_encoder.classes_\n",
        "for cls_name, orig, capped in zip(class_names, class_weights, class_weights_capped):\n",
        "    print(f\"  {cls_name:20s}: {orig:7.2f} -> {capped:5.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6H9cQeLkADk",
        "outputId": "5da355b4-21b8-4469-d340-07a276a198e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# After moving to GPU\n",
        "class_weights_tensor = class_weights_tensor.to('cuda')\n",
        "\n",
        "# Check device\n",
        "print(class_weights_tensor.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Xy6cGM0mbT8z"
      },
      "outputs": [],
      "source": [
        "# 3. Smaller model with higher dropout\n",
        "model_v2 = SplendorMLP(input_dim=144, hidden1=128, hidden2=64, num_classes=4, dropout=0.4)\n",
        "# Move model to GPU\n",
        "model_v2 = model_v2.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbmyKsY3bXlu",
        "outputId": "83f53aae-77c0-4f4c-97a8-3404cc964226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model architecture: 144 → 128 → 64 → 4\n",
            "Total parameters: 27,460\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nModel architecture: 144 → 128 → 64 → 4\")\n",
        "print(f\"Total parameters: {sum(p.numel() for p in model_v2.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "TH0WGwZibb8t"
      },
      "outputs": [],
      "source": [
        "#4. Define Loss, Optimizer with L2 Regularization and scheduler\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "optimizer = optim.Adam(model_v2.parameters(), lr=0.001, weight_decay=1e-4)  # L2 regularization\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kiss6dEvaQk2",
        "outputId": "6b3120ac-cf54-44a9-dbde-50dd26a6a220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training...\n",
            "================================================================================\n",
            "  ✓ New best Val F1: 0.1902 (saved)\n",
            "  ✓ New best Val F1: 0.1933 (saved)\n",
            "Epoch [5/100]\n",
            "  Train Loss: 0.7831, Train Acc: 61.41%\n",
            "  Val Loss:   1.4557, Val Acc:   30.54%, F1: 0.1925\n",
            "  ✓ New best Val F1: 0.1947 (saved)\n",
            "Epoch [10/100]\n",
            "  Train Loss: 0.7155, Train Acc: 62.67%\n",
            "  Val Loss:   1.4497, Val Acc:   30.57%, F1: 0.1942\n",
            "Epoch [15/100]\n",
            "  Train Loss: 0.6713, Train Acc: 63.90%\n",
            "  Val Loss:   1.4581, Val Acc:   30.37%, F1: 0.1921\n",
            "Epoch [20/100]\n",
            "  Train Loss: 0.6462, Train Acc: 64.39%\n",
            "  Val Loss:   1.4620, Val Acc:   30.33%, F1: 0.1921\n",
            "\n",
            "Early stopping at epoch 23\n",
            "\n",
            "================================================================================\n",
            "Training complete!\n",
            "Best validation F1: 0.1947\n",
            "Best validation loss: 1.4547\n"
          ]
        }
      ],
      "source": [
        "# 5. TRAINING LOOP WITH GPU SUPPORT AND VALIDATION SET\n",
        "\n",
        "num_epochs = 100\n",
        "best_val_loss = float('inf')\n",
        "best_val_f1 = 0.0\n",
        "patience_counter = 0\n",
        "early_stop_patience = 15\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model_v2.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        # Move batch to GPU\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        outputs = model_v2(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        train_total += y_batch.size(0)\n",
        "        train_correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    train_accuracy = 100 * train_correct / train_total\n",
        "\n",
        "    # Validation phase\n",
        "    model_v2.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    all_val_preds = []\n",
        "    all_val_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            # Move batch to GPU\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_total += y_batch.size(0)\n",
        "            val_correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "            # Move predictions back to CPU for sklearn\n",
        "            all_val_preds.extend(predicted.cpu().numpy())\n",
        "            all_val_targets.extend(y_batch.cpu().numpy())\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "\n",
        "    # Calculate macro F1-score\n",
        "    from sklearn.metrics import f1_score\n",
        "    val_f1_macro = f1_score(all_val_targets, all_val_preds, average='macro')\n",
        "\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    # Print progress every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "        print(f\"  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}%\")\n",
        "        print(f\"  Val Loss:   {avg_val_loss:.4f}, Val Acc:   {val_accuracy:.2f}%, F1: {val_f1_macro:.4f}\")\n",
        "\n",
        "    # Early stopping based on validation F1\n",
        "    if val_f1_macro > best_val_f1:\n",
        "        best_val_f1 = val_f1_macro\n",
        "        best_val_loss = avg_val_loss\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), 'best_splendor_model_v2.pth')\n",
        "        print(f\"  ✓ New best Val F1: {val_f1_macro:.4f} (saved)\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= early_stop_patience:\n",
        "        print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Training complete!\")\n",
        "print(f\"Best validation F1: {best_val_f1:.4f}\")\n",
        "print(f\"Best validation loss: {best_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final evaluation on test set\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Evaluating on test set...\")\n",
        "model_v2.load_state_dict(torch.load('best_splendor_model_v2.pth'))\n",
        "model_v2.eval()\n",
        "\n",
        "test_loss = 0.0\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "all_test_preds = []\n",
        "all_test_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        outputs = model_v2(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_total += y_batch.size(0)\n",
        "        test_correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "        all_test_preds.extend(predicted.cpu().numpy())\n",
        "        all_test_targets.extend(y_batch.cpu().numpy())\n",
        "\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "\n",
        "# Import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "# Calculate various metrics\n",
        "test_f1_macro = f1_score(all_test_targets, all_test_preds, average='macro')\n",
        "test_f1_weighted = f1_score(all_test_targets, all_test_preds, average='weighted')\n",
        "test_precision_macro = precision_score(all_test_targets, all_test_preds, average='macro')\n",
        "test_recall_macro = recall_score(all_test_targets, all_test_preds, average='macro')\n",
        "\n",
        "print(f\"\\nTest Loss: {avg_test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "print(f\"\\nMacro Metrics:\")\n",
        "print(f\"  Precision: {test_precision_macro:.4f}\")\n",
        "print(f\"  Recall:    {test_recall_macro:.4f}\")\n",
        "print(f\"  F1-Score:  {test_f1_macro:.4f}\")\n",
        "print(f\"\\nWeighted F1-Score: {test_f1_weighted:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(\"=\"*80)\n",
        "class_names = ['build', 'reserve', 'take 2 tokens', 'take 3 tokens']\n",
        "print(classification_report(all_test_targets, all_test_preds,\n",
        "                          target_names=class_names,\n",
        "                          digits=2))\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"=\"*80)\n",
        "print(\"CONFUSION MATRIX\")\n",
        "print(\"=\"*80)\n",
        "cm = confusion_matrix(all_test_targets, all_test_preds)\n",
        "print(f\"{'':>20}\", end='')\n",
        "for name in class_names:\n",
        "    print(f\"{name:>15}\", end='')\n",
        "print()\n",
        "for i, name in enumerate(class_names):\n",
        "    print(f\"{name:>20}\", end='')\n",
        "    for j in range(len(class_names)):\n",
        "        print(f\"{cm[i][j]:>15}\", end='')\n",
        "    print()\n",
        "\n",
        "# Prediction vs Actual distribution\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PREDICTION vs ACTUAL DISTRIBUTION\")\n",
        "print(\"=\"*80)\n",
        "unique_actual, counts_actual = np.unique(all_test_targets, return_counts=True)\n",
        "unique_pred, counts_pred = np.unique(all_test_preds, return_counts=True)\n",
        "\n",
        "# Create dict for easy lookup\n",
        "pred_dict = dict(zip(unique_pred, counts_pred))\n",
        "\n",
        "for i, name in enumerate(class_names):\n",
        "    actual_count = counts_actual[i] if i < len(counts_actual) else 0\n",
        "    pred_count = pred_dict.get(i, 0)\n",
        "    print(f\"{name:>20} - Predicted: {pred_count:>5}, Actual: {actual_count:>5}\")\n",
        "\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1UvgbiKHzqi",
        "outputId": "2be7c77d-2f6b-448d-d783-806395e53892"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Loss: 1.4118\n",
            "Test Accuracy: 31.60%\n",
            "\n",
            "Macro Metrics:\n",
            "  Precision: 0.2205\n",
            "  Recall:    0.2088\n",
            "  F1-Score:  0.1877\n",
            "\n",
            "Weighted F1-Score: 0.3460\n",
            "\n",
            "================================================================================\n",
            "CLASSIFICATION REPORT\n",
            "================================================================================\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        build       0.43      0.20      0.27     15824\n",
            "      reserve       0.00      0.08      0.00        24\n",
            "take 2 tokens       0.02      0.09      0.03       799\n",
            "take 3 tokens       0.44      0.46      0.45     13889\n",
            "\n",
            "     accuracy                           0.32     30536\n",
            "    macro avg       0.22      0.21      0.19     30536\n",
            " weighted avg       0.42      0.32      0.35     30536\n",
            "\n",
            "================================================================================\n",
            "CONFUSION MATRIX\n",
            "================================================================================\n",
            "                              build        reserve  take 2 tokens  take 3 tokens\n",
            "               build           3140           2232           2558           7894\n",
            "             reserve              3              2              7             12\n",
            "       take 2 tokens            302            103             72            322\n",
            "       take 3 tokens           3926           1864           1665           6434\n",
            "\n",
            "================================================================================\n",
            "PREDICTION vs ACTUAL DISTRIBUTION\n",
            "================================================================================\n",
            "               build - Predicted:  7371, Actual: 15824\n",
            "             reserve - Predicted:  4201, Actual:    24\n",
            "       take 2 tokens - Predicted:  4302, Actual:   799\n",
            "       take 3 tokens - Predicted: 14662, Actual: 13889\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Architecture 2: 128 → 64 → 4, dropout 0.4\n",
        "Accuracy: 31.6%\n",
        "\n",
        "Macro F1: 0.19 (weighted F1: 0.35)\n",
        "\n",
        "Strengths:\n",
        "\n",
        "More balanced predictions across classes (less extreme bias toward majority).\n",
        "\n",
        "Slightly better recall for take 3 tokens (0.46 vs 0.54 previously).\n",
        "\n",
        "Weaknesses:\n",
        "\n",
        "Overall accuracy collapsed (from 63% → 32%).\n",
        "\n",
        "Precision and recall for rare classes dropped to near zero.\n",
        "\n",
        "Severe misclassification: reserve predicted 4,201 times vs only 24 actual.\n",
        "\n",
        "Interpretation: The smaller, regularized model underfits — it lost the ability to capture strong patterns, leading to poor accuracy and weak minority class handling."
      ],
      "metadata": {
        "id": "LwluV-6JNltV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)![image.png]()"
      ],
      "metadata": {
        "id": "PtKW1rFgNqOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The larger model (256→128) performs better overall, but suffers from false positives on rare classes.\n",
        "\n",
        "The smaller model (128→64) is too constrained and underfits, leading to poor accuracy and collapse in minority class performance.\n",
        "\n",
        "Accuracy alone is misleading — macro F1 shows both models fail to handle imbalance well."
      ],
      "metadata": {
        "id": "c4pV8x9ROJg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Focal Loss implementation\n",
        "\n",
        "- Focus learning on hard-to-classify examples while being much less aggressive than inverse frequency weighting, preventing the massive overprediction. It avoids exploding gradients and massive overprediction of rare classes.\n",
        "\n",
        "- Oversampling for only the two minority classes (reserve and take 2 tokens) by duplicating them 3-5x in the training set. This gives the model more exposure to rare patterns without distorting the distribution too much."
      ],
      "metadata": {
        "id": "CO45gH0WOKqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Define Focal Loss class and calculate effective class weights\n",
        "# Focal Loss modifies CrossEntropyLoss by adding a focusing term\n",
        "\n",
        "import torch.nn.functional as F\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        return focal_loss"
      ],
      "metadata": {
        "id": "lFKsbwJJRGHx"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Oversample minority classes (reserve 5x, take 2 tokens 3x) to give the model more exposure without extreme weight changes\n",
        "def get_effective_weights(class_counts, beta=0.999):\n",
        "    effective_num = 1.0 - np.power(beta, class_counts)\n",
        "    weights = (1.0 - beta) / effective_num\n",
        "    weights = weights / weights.sum() * len(weights)\n",
        "    return weights\n",
        "\n",
        "# Get counts for each class using your y_train_indices\n",
        "class_counts = np.array([\n",
        "    (y_train_indices == 0).sum(),  # build\n",
        "    (y_train_indices == 1).sum(),  # reserve\n",
        "    (y_train_indices == 2).sum(),  # take 2 tokens\n",
        "    (y_train_indices == 3).sum()   # take 3 tokens\n",
        "])"
      ],
      "metadata": {
        "id": "p7asBFh4SF-9"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Class counts in training set:\")\n",
        "for i, label in enumerate(label_encoder.classes_):\n",
        "    print(f\"  {i}: {label:20} {class_counts[i]:6d} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bU0_vosSdox",
        "outputId": "c2c64506-730c-4e0f-ec21-2470456fec4a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts in training set:\n",
            "  0: build                 73841 samples\n",
            "  1: reserve                 113 samples\n",
            "  2: take 2 tokens          3730 samples\n",
            "  3: take 3 tokens         64813 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate weights with beta=0.999\n",
        "class_weights = get_effective_weights(class_counts, beta=0.999)\n",
        "class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
        "\n",
        "print(\"\\nClass weights (effective number method):\")\n",
        "for i, label in enumerate(label_encoder.classes_):\n",
        "    print(f\"  {i}: {label:20} weight: {class_weights[i]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9v004DRTjJw",
        "outputId": "fa2a8202-5841-4a86-c697-34f44fec2cb9"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class weights (effective number method):\n",
            "  0: build                weight: 0.3231\n",
            "  1: reserve              weight: 3.0227\n",
            "  2: take 2 tokens        weight: 0.3311\n",
            "  3: take 3 tokens        weight: 0.3231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Oversample Minority Classes"
      ],
      "metadata": {
        "id": "k8It9UNpUqFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tensors back to numpy for oversampling\n",
        "X_train_np = X_train_tensor.cpu().numpy()\n",
        "y_train_np = y_train_tensor.cpu().numpy()\n",
        "\n",
        "X_train_oversampled = X_train_np.copy()\n",
        "y_train_oversampled = y_train_np.copy()"
      ],
      "metadata": {
        "id": "PetEpLEuUmfg"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Oversample reserve class (class 1) - duplicate 5x\n",
        "reserve_indices = np.where(y_train_np == 1)[0]\n",
        "print(f\"Found {len(reserve_indices)} reserve samples, duplicating 5x...\")\n",
        "for _ in range(4):  # 4 more times = 5x total\n",
        "    X_train_oversampled = np.vstack([X_train_oversampled, X_train_np[reserve_indices]])\n",
        "    y_train_oversampled = np.concatenate([y_train_oversampled, y_train_np[reserve_indices]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUhhlnjkUvEz",
        "outputId": "31ae3834-8323-4235-8c7a-35b59b3b68a4"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 113 reserve samples, duplicating 5x...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Oversample take 2 tokens (class 2) - duplicate 3x\n",
        "take2_indices = np.where(y_train_np == 2)[0]\n",
        "print(f\"Found {len(take2_indices)} take 2 tokens samples, duplicating 3x...\")\n",
        "for _ in range(2):  # 2 more times = 3x total\n",
        "    X_train_oversampled = np.vstack([X_train_oversampled, X_train_np[take2_indices]])\n",
        "    y_train_oversampled = np.concatenate([y_train_oversampled, y_train_np[take2_indices]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSzHQ53QUx0R",
        "outputId": "7a06c5b8-b14b-43bd-ed0f-3667d6a15a6b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3730 take 2 tokens samples, duplicating 3x...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nOriginal training set: {len(y_train_np)} samples\")\n",
        "print(f\"Oversampled training set: {len(y_train_oversampled)} samples\")\n",
        "print(f\"Increase: {len(y_train_oversampled) - len(y_train_np)} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXAPkbNsU2Bx",
        "outputId": "46fc6434-85d3-4923-fb0c-24b4d76afad9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original training set: 142497 samples\n",
            "Oversampled training set: 150409 samples\n",
            "Increase: 7912 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nNew class distribution:\")\n",
        "for i, label in enumerate(label_encoder.classes_):\n",
        "    count = (y_train_oversampled == i).sum()\n",
        "    pct = 100 * count / len(y_train_oversampled)\n",
        "    print(f\"  {i}: {label:20} {count:6d} ({pct:5.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BnOM4P2U9em",
        "outputId": "971e1023-03d1-4472-a83d-6cce2531bcfa"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New class distribution:\n",
            "  0: build                 73841 (49.09%)\n",
            "  1: reserve                 565 ( 0.38%)\n",
            "  2: take 2 tokens         11190 ( 7.44%)\n",
            "  3: take 3 tokens         64813 (43.09%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new dataset with oversampled data\n",
        "train_dataset_oversampled = TensorDataset(\n",
        "    torch.FloatTensor(X_train_oversampled),\n",
        "    torch.LongTensor(y_train_oversampled)\n",
        ")\n",
        "\n",
        "train_loader_oversampled = DataLoader(\n",
        "    train_dataset_oversampled,\n",
        "    batch_size=256,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "print(f\"\\nNew train loader created with {len(train_loader_oversampled)} batches\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRombUbsVTy3",
        "outputId": "1b99eeb0-4533-4f37-9ba9-77ee9b9f699d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New train loader created with 588 batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Model with Focal Loss"
      ],
      "metadata": {
        "id": "HHPLst1bV7HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate model with my architecture\n",
        "model_focal = SplendorMLP(\n",
        "    input_dim=144,\n",
        "    hidden1=256,\n",
        "    hidden2=128,\n",
        "    num_classes=4,\n",
        "    dropout=0.3\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "KHC-EySCVVpd"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Focal Loss with gamma=1.5 and class weights\n",
        "criterion_focal = FocalLoss(alpha=class_weights_tensor, gamma=1.5)"
      ],
      "metadata": {
        "id": "NdU0Xa2VWEaP"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer\n",
        "optimizer_focal = optim.AdamW(\n",
        "    model_focal.parameters(),\n",
        "    lr=0.001,\n",
        "    weight_decay=0.01\n",
        ")"
      ],
      "metadata": {
        "id": "8SZhwQ_nWFUp"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate scheduler\n",
        "scheduler_focal = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer_focal,\n",
        "    mode='max',\n",
        "    factor=0.5,\n",
        "    patience=5\n",
        ")"
      ],
      "metadata": {
        "id": "hjOo6Z2uWPIu"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model initialized with Focal Loss\")\n",
        "print(f\"  Architecture: 144 -> 256 -> 128 -> 4\")\n",
        "print(f\"  Gamma: 1.5\")\n",
        "print(f\"  Dropout: 0.3\")\n",
        "print(f\"  Using oversampled training data: {len(y_train_oversampled):,} samples\")\n",
        "print(f\"  Model parameters: {sum(p.numel() for p in model_focal.parameters()):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-i_5A5pWSAA",
        "outputId": "9171f8f7-02ec-4f31-9f34-b0e417560b22"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model initialized with Focal Loss\n",
            "  Architecture: 144 -> 256 -> 128 -> 4\n",
            "  Gamma: 1.5\n",
            "  Dropout: 0.3\n",
            "  Using oversampled training data: 150,409 samples\n",
            "  Model parameters: 71,300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop with validation set"
      ],
      "metadata": {
        "id": "SaAz0T9IWusv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "#Training Loop with Focal Loss (GPU)\n",
        "# ============================================================================\n",
        "num_epochs = 50\n",
        "best_val_f1 = 0.0\n",
        "patience_counter = 0\n",
        "early_stop_patience = 20\n",
        "\n",
        "train_losses = []\n",
        "val_f1_scores = []\n",
        "val_losses = []\n",
        "\n",
        "print(\"Starting training...\")\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"Epochs: {num_epochs}\")\n",
        "print(f\"Batch size: 256\")\n",
        "print(f\"Early stopping patience: {early_stop_patience}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # ==================== Training Phase ====================\n",
        "    model_focal.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader_oversampled:\n",
        "        # Move to GPU\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer_focal.zero_grad()\n",
        "        outputs = model_focal(X_batch)\n",
        "        loss = criterion_focal(outputs, y_batch)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping to prevent exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model_focal.parameters(), max_norm=1.0)\n",
        "\n",
        "        # Update weights\n",
        "        optimizer_focal.step()\n",
        "\n",
        "        # Track metrics\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        train_total += y_batch.size(0)\n",
        "        train_correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader_oversampled)\n",
        "    train_accuracy = 100 * train_correct / train_total\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # ==================== Validation Phase ====================\n",
        "    model_focal.eval()\n",
        "    val_loss = 0.0\n",
        "    val_preds = []\n",
        "    val_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            # Move to GPU\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model_focal(X_batch)\n",
        "            loss = criterion_focal(outputs, y_batch)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            # Store predictions for metrics\n",
        "            val_preds.extend(predicted.cpu().numpy())\n",
        "            val_targets.extend(y_batch.cpu().numpy())\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "\n",
        "    # Calculate metrics\n",
        "    from sklearn.metrics import f1_score, accuracy_score\n",
        "    val_f1_macro = f1_score(val_targets, val_preds, average='macro')\n",
        "    val_f1_weighted = f1_score(val_targets, val_preds, average='weighted')\n",
        "    val_accuracy = 100 * accuracy_score(val_targets, val_preds)\n",
        "    val_f1_scores.append(val_f1_macro)\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler_focal.step(val_f1_macro)\n",
        "    current_lr = optimizer_focal.param_groups[0]['lr']\n",
        "\n",
        "    # Print progress\n",
        "    print(f\"Epoch {epoch+1:2d}/{num_epochs} | \"\n",
        "          f\"Train Loss: {avg_train_loss:.4f} | \"\n",
        "          f\"Train Acc: {train_accuracy:.2f}% | \"\n",
        "          f\"Val Loss: {avg_val_loss:.4f} | \"\n",
        "          f\"Val Acc: {val_accuracy:.2f}% | \"\n",
        "          f\"Val F1 (macro): {val_f1_macro:.4f} | \"\n",
        "          f\"Val F1 (weighted): {val_f1_weighted:.4f} | \"\n",
        "          f\"LR: {current_lr:.6f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_f1_macro > best_val_f1:\n",
        "        best_val_f1 = val_f1_macro\n",
        "        torch.save(model_focal.state_dict(), 'best_splendor_focal_model.pth')\n",
        "        patience_counter = 0\n",
        "        print(f\"  ✓ New best model saved! (F1: {best_val_f1:.4f})\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stop_patience:\n",
        "            print(f\"\\nEarly stopping triggered at epoch {epoch+1}\")\n",
        "            print(f\"Best validation F1: {best_val_f1:.4f}\")\n",
        "            break\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Training complete!\")\n",
        "print(f\"Best validation F1 (macro): {best_val_f1:.4f}\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl9ud2t5WV5z",
        "outputId": "3f9ed543-ad1f-46ad-a9dc-f77742e79c6a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Device: cuda\n",
            "Epochs: 50\n",
            "Batch size: 256\n",
            "Early stopping patience: 20\n",
            "================================================================================\n",
            "Epoch  1/50 | Train Loss: 0.0192 | Train Acc: 73.84% | Val Loss: 0.0320 | Val Acc: 74.75% | Val F1 (macro): 0.5096 | Val F1 (weighted): 0.7495 | LR: 0.000500\n",
            "  ✓ New best model saved! (F1: 0.5096)\n",
            "Epoch  2/50 | Train Loss: 0.0191 | Train Acc: 74.00% | Val Loss: 0.0327 | Val Acc: 75.23% | Val F1 (macro): 0.5097 | Val F1 (weighted): 0.7537 | LR: 0.000250\n",
            "  ✓ New best model saved! (F1: 0.5097)\n",
            "Epoch  3/50 | Train Loss: 0.0187 | Train Acc: 74.29% | Val Loss: 0.0320 | Val Acc: 75.05% | Val F1 (macro): 0.5228 | Val F1 (weighted): 0.7504 | LR: 0.000250\n",
            "  ✓ New best model saved! (F1: 0.5228)\n",
            "Epoch  4/50 | Train Loss: 0.0185 | Train Acc: 74.48% | Val Loss: 0.0326 | Val Acc: 74.94% | Val F1 (macro): 0.5045 | Val F1 (weighted): 0.7497 | LR: 0.000250\n",
            "Epoch  5/50 | Train Loss: 0.0184 | Train Acc: 74.62% | Val Loss: 0.0326 | Val Acc: 75.00% | Val F1 (macro): 0.4968 | Val F1 (weighted): 0.7505 | LR: 0.000250\n",
            "Epoch  6/50 | Train Loss: 0.0184 | Train Acc: 74.63% | Val Loss: 0.0342 | Val Acc: 74.78% | Val F1 (macro): 0.5130 | Val F1 (weighted): 0.7500 | LR: 0.000250\n",
            "Epoch  7/50 | Train Loss: 0.0182 | Train Acc: 74.63% | Val Loss: 0.0333 | Val Acc: 74.63% | Val F1 (macro): 0.5157 | Val F1 (weighted): 0.7481 | LR: 0.000250\n",
            "Epoch  8/50 | Train Loss: 0.0180 | Train Acc: 74.78% | Val Loss: 0.0340 | Val Acc: 74.35% | Val F1 (macro): 0.5062 | Val F1 (weighted): 0.7478 | LR: 0.000250\n",
            "Epoch  9/50 | Train Loss: 0.0179 | Train Acc: 74.86% | Val Loss: 0.0342 | Val Acc: 74.34% | Val F1 (macro): 0.5062 | Val F1 (weighted): 0.7467 | LR: 0.000125\n",
            "Epoch 10/50 | Train Loss: 0.0178 | Train Acc: 75.02% | Val Loss: 0.0356 | Val Acc: 74.54% | Val F1 (macro): 0.5021 | Val F1 (weighted): 0.7482 | LR: 0.000125\n",
            "Epoch 11/50 | Train Loss: 0.0177 | Train Acc: 75.03% | Val Loss: 0.0342 | Val Acc: 74.52% | Val F1 (macro): 0.5063 | Val F1 (weighted): 0.7482 | LR: 0.000125\n",
            "Epoch 12/50 | Train Loss: 0.0178 | Train Acc: 74.95% | Val Loss: 0.0328 | Val Acc: 74.72% | Val F1 (macro): 0.5196 | Val F1 (weighted): 0.7500 | LR: 0.000125\n",
            "Epoch 13/50 | Train Loss: 0.0176 | Train Acc: 75.00% | Val Loss: 0.0351 | Val Acc: 74.45% | Val F1 (macro): 0.4962 | Val F1 (weighted): 0.7463 | LR: 0.000125\n",
            "Epoch 14/50 | Train Loss: 0.0177 | Train Acc: 75.08% | Val Loss: 0.0351 | Val Acc: 74.64% | Val F1 (macro): 0.5067 | Val F1 (weighted): 0.7485 | LR: 0.000125\n",
            "Epoch 15/50 | Train Loss: 0.0176 | Train Acc: 75.12% | Val Loss: 0.0352 | Val Acc: 74.70% | Val F1 (macro): 0.5101 | Val F1 (weighted): 0.7490 | LR: 0.000063\n",
            "Epoch 16/50 | Train Loss: 0.0176 | Train Acc: 75.23% | Val Loss: 0.0351 | Val Acc: 74.51% | Val F1 (macro): 0.5039 | Val F1 (weighted): 0.7487 | LR: 0.000063\n",
            "Epoch 17/50 | Train Loss: 0.0175 | Train Acc: 75.13% | Val Loss: 0.0363 | Val Acc: 74.67% | Val F1 (macro): 0.4984 | Val F1 (weighted): 0.7490 | LR: 0.000063\n",
            "Epoch 18/50 | Train Loss: 0.0176 | Train Acc: 75.28% | Val Loss: 0.0359 | Val Acc: 74.87% | Val F1 (macro): 0.4982 | Val F1 (weighted): 0.7506 | LR: 0.000063\n",
            "Epoch 19/50 | Train Loss: 0.0175 | Train Acc: 75.30% | Val Loss: 0.0364 | Val Acc: 74.46% | Val F1 (macro): 0.4955 | Val F1 (weighted): 0.7460 | LR: 0.000063\n",
            "Epoch 20/50 | Train Loss: 0.0174 | Train Acc: 75.30% | Val Loss: 0.0372 | Val Acc: 74.79% | Val F1 (macro): 0.4991 | Val F1 (weighted): 0.7492 | LR: 0.000063\n",
            "Epoch 21/50 | Train Loss: 0.0174 | Train Acc: 75.23% | Val Loss: 0.0369 | Val Acc: 74.49% | Val F1 (macro): 0.4860 | Val F1 (weighted): 0.7483 | LR: 0.000031\n",
            "Epoch 22/50 | Train Loss: 0.0173 | Train Acc: 75.41% | Val Loss: 0.0368 | Val Acc: 74.92% | Val F1 (macro): 0.4995 | Val F1 (weighted): 0.7512 | LR: 0.000031\n",
            "Epoch 23/50 | Train Loss: 0.0173 | Train Acc: 75.60% | Val Loss: 0.0374 | Val Acc: 74.69% | Val F1 (macro): 0.4876 | Val F1 (weighted): 0.7489 | LR: 0.000031\n",
            "\n",
            "Early stopping triggered at epoch 23\n",
            "Best validation F1: 0.5228\n",
            "\n",
            "================================================================================\n",
            "Training complete!\n",
            "Best validation F1 (macro): 0.5228\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Set Evaluation"
      ],
      "metadata": {
        "id": "Vq91FTzMYh6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model\n",
        "model_focal.load_state_dict(torch.load('best_splendor_focal_model.pth'))\n",
        "model_focal.eval()\n",
        "\n",
        "# Evaluation\n",
        "test_loss = 0.0\n",
        "test_preds = []\n",
        "test_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        # Move to GPU\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model_focal(X_batch)\n",
        "        loss = criterion_focal(outputs, y_batch)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Store predictions\n",
        "        test_preds.extend(predicted.cpu().numpy())\n",
        "        test_targets.extend(y_batch.cpu().numpy())\n",
        "\n",
        "# Calculate metrics\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "test_accuracy = 100 * accuracy_score(test_targets, test_preds)\n",
        "test_f1_macro = f1_score(test_targets, test_preds, average='macro')\n",
        "test_f1_weighted = f1_score(test_targets, test_preds, average='weighted')\n",
        "test_precision_macro = precision_score(test_targets, test_preds, average='macro')\n",
        "test_recall_macro = recall_score(test_targets, test_preds, average='macro')\n",
        "\n",
        "print(f\"\\nTest Loss: {avg_test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "print(f\"\\nMacro Metrics:\")\n",
        "print(f\"  Precision: {test_precision_macro:.4f}\")\n",
        "print(f\"  Recall:    {test_recall_macro:.4f}\")\n",
        "print(f\"  F1-Score:  {test_f1_macro:.4f}\")\n",
        "print(f\"\\nWeighted F1-Score: {test_f1_weighted:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eO734AdYfG1",
        "outputId": "38b713a2-9477-4736-b325-717acf0d3fd3"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Loss: 0.0353\n",
            "Test Accuracy: 74.61%\n",
            "\n",
            "Macro Metrics:\n",
            "  Precision: 0.5102\n",
            "  Recall:    0.5469\n",
            "  F1-Score:  0.5211\n",
            "\n",
            "Weighted F1-Score: 0.7467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Set Detailed Analysis\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CLASSIFICATION REPORT (TEST SET)\")\n",
        "print(\"=\"*80)\n",
        "print(classification_report(\n",
        "    test_targets,\n",
        "    test_preds,\n",
        "    target_names=label_encoder.classes_,\n",
        "    digits=4\n",
        "))\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"CONFUSION MATRIX (TEST SET)\")\n",
        "print(\"=\"*80)\n",
        "cm = confusion_matrix(test_targets, test_preds)\n",
        "print(f\"{'':>20}\", end='')\n",
        "for label in label_encoder.classes_:\n",
        "    print(f\"{label:>15}\", end='')\n",
        "print()\n",
        "for i, label in enumerate(label_encoder.classes_):\n",
        "    print(f\"{label:>20}\", end='')\n",
        "    for j in range(len(label_encoder.classes_)):\n",
        "        print(f\"{cm[i][j]:>15}\", end='')\n",
        "    print()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PREDICTION vs ACTUAL DISTRIBUTION (TEST SET)\")\n",
        "print(\"=\"*80)\n",
        "unique_actual, counts_actual = np.unique(test_targets, return_counts=True)\n",
        "unique_pred, counts_pred = np.unique(test_preds, return_counts=True)\n",
        "\n",
        "pred_dict = dict(zip(unique_pred, counts_pred))\n",
        "\n",
        "for i, label in enumerate(label_encoder.classes_):\n",
        "    actual_count = counts_actual[i] if i < len(counts_actual) else 0\n",
        "    pred_count = pred_dict.get(i, 0)\n",
        "    ratio = pred_count / actual_count if actual_count > 0 else 0\n",
        "    print(f\"{label:>20} | Predicted: {pred_count:>5} | Actual: {actual_count:>5} | Ratio: {ratio:.2f}x\")\n",
        "\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StFUNgbjY14h",
        "outputId": "f54a2967-bbb9-4088-810e-52dbc6c8d4df"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "CLASSIFICATION REPORT (TEST SET)\n",
            "================================================================================\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        build     0.7561    0.8555    0.8027     15824\n",
            "      reserve     0.2759    0.3333    0.3019        24\n",
            "take 2 tokens     0.2162    0.3542    0.2685       799\n",
            "take 3 tokens     0.7929    0.6446    0.7111     13889\n",
            "\n",
            "     accuracy                         0.7461     30536\n",
            "    macro avg     0.5102    0.5469    0.5211     30536\n",
            " weighted avg     0.7583    0.7461    0.7467     30536\n",
            "\n",
            "================================================================================\n",
            "CONFUSION MATRIX (TEST SET)\n",
            "================================================================================\n",
            "                              build        reserve  take 2 tokens  take 3 tokens\n",
            "               build          13538              3            275           2008\n",
            "             reserve             12              8              0              4\n",
            "       take 2 tokens            189              0            283            327\n",
            "       take 3 tokens           4167             18            751           8953\n",
            "\n",
            "================================================================================\n",
            "PREDICTION vs ACTUAL DISTRIBUTION (TEST SET)\n",
            "================================================================================\n",
            "               build | Predicted: 17906 | Actual: 15824 | Ratio: 1.13x\n",
            "             reserve | Predicted:    29 | Actual:    24 | Ratio: 1.21x\n",
            "       take 2 tokens | Predicted:  1309 | Actual:   799 | Ratio: 1.64x\n",
            "       take 3 tokens | Predicted: 11292 | Actual: 13889 | Ratio: 0.81x\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Focal Loss + Oversampling achieved target performance\n",
        "\n",
        "- Improved accuracy from 63% → 74.6% (+11.6 percentage points)\n",
        "- Improved macro F1 from 0.41 → 0.52 (+27%)\n",
        "- Balanced predictions: reserve ratio 1.21x vs 20.8x previously\n",
        "- Successfully learned minority classes without collapsing majority class performance"
      ],
      "metadata": {
        "id": "nKcYn5p5Z9Lk"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}