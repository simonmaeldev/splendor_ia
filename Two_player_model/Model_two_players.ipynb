{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x0IDQ2ZQMa4"
      },
      "source": [
        "### Model for 2 players only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "6EMTEY3DQRzr",
        "outputId": "d7e55490-bdca-4a0c-911c-b61a92178389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Checking folder: /content/drive/MyDrive/Colab Notebooks/DL2_model/2_games\n",
            "Found 3500 CSV files\n",
            "Combined DataFrame shape: (203568, 403)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   game_id  num_players  turn_number  current_player  gems_board_white  \\\n",
              "0        1            2            1               0                 4   \n",
              "1        1            2            1               1                 4   \n",
              "2        1            2            2               0                 3   \n",
              "3        1            2            2               1                 2   \n",
              "4        1            2            3               0                 1   \n",
              "\n",
              "   gems_board_blue  gems_board_green  gems_board_red  gems_board_black  \\\n",
              "0                4                 4               4                 4   \n",
              "1                4                 4               2                 4   \n",
              "2                3                 4               2                 3   \n",
              "3                2                 3               2                 3   \n",
              "4                1                 2               2                 3   \n",
              "\n",
              "   gems_board_gold  ...  gem_take2_green  gem_take2_red  gem_take2_black  \\\n",
              "0                5  ...              0.0            2.0              0.0   \n",
              "1                5  ...              NaN            NaN              NaN   \n",
              "2                5  ...              NaN            NaN              NaN   \n",
              "3                5  ...              NaN            NaN              NaN   \n",
              "4                5  ...              NaN            NaN              NaN   \n",
              "\n",
              "   noble_selection  gems_removed_white  gems_removed_blue  gems_removed_green  \\\n",
              "0               -1                   0                  0                   0   \n",
              "1               -1                   0                  0                   0   \n",
              "2               -1                   0                  0                   0   \n",
              "3               -1                   0                  0                   0   \n",
              "4               -1                   0                  0                   0   \n",
              "\n",
              "   gems_removed_red  gems_removed_black  gems_removed_gold  \n",
              "0                 0                   0                  0  \n",
              "1                 0                   0                  0  \n",
              "2                 0                   0                  0  \n",
              "3                 0                   0                  0  \n",
              "4                 0                   0                  0  \n",
              "\n",
              "[5 rows x 403 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d63dc3a1-0b0e-4e90-8dbc-e3ff24cd0362\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>game_id</th>\n",
              "      <th>num_players</th>\n",
              "      <th>turn_number</th>\n",
              "      <th>current_player</th>\n",
              "      <th>gems_board_white</th>\n",
              "      <th>gems_board_blue</th>\n",
              "      <th>gems_board_green</th>\n",
              "      <th>gems_board_red</th>\n",
              "      <th>gems_board_black</th>\n",
              "      <th>gems_board_gold</th>\n",
              "      <th>...</th>\n",
              "      <th>gem_take2_green</th>\n",
              "      <th>gem_take2_red</th>\n",
              "      <th>gem_take2_black</th>\n",
              "      <th>noble_selection</th>\n",
              "      <th>gems_removed_white</th>\n",
              "      <th>gems_removed_blue</th>\n",
              "      <th>gems_removed_green</th>\n",
              "      <th>gems_removed_red</th>\n",
              "      <th>gems_removed_black</th>\n",
              "      <th>gems_removed_gold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 403 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d63dc3a1-0b0e-4e90-8dbc-e3ff24cd0362')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d63dc3a1-0b0e-4e90-8dbc-e3ff24cd0362 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d63dc3a1-0b0e-4e90-8dbc-e3ff24cd0362');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-762aa91f-37e6-44dd-ac9c-383f8c1e5675\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-762aa91f-37e6-44dd-ac9c-383f8c1e5675')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-762aa91f-37e6-44dd-ac9c-383f8c1e5675 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 1. Start by loading all the csv files of 2 players in a dataframe\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path structure in Google Drive\n",
        "games_folder = Path(\"/content/drive/MyDrive/Colab Notebooks/DL2_model/2_games\")\n",
        "\n",
        "print(\"Checking folder:\", games_folder)\n",
        "\n",
        "#Load the Files\n",
        "\n",
        "if not games_folder.exists():\n",
        "    print(\"Error: Folder does not exist.\")\n",
        "else:\n",
        "    csv_files = sorted(games_folder.glob(\"*.csv\"))\n",
        "    print(f\"Found {len(csv_files)} CSV files\")\n",
        "\n",
        "    if len(csv_files) == 0:\n",
        "        print(\"No csv files found in folder\")\n",
        "    else:\n",
        "        dfs = [pd.read_csv(file) for file in csv_files]\n",
        "        combined_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "        print(\"Combined DataFrame shape:\", combined_df.shape)\n",
        "        display(combined_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W43fJvmG5Au0"
      },
      "source": [
        "### 1. Feature engineering\n",
        "\n",
        "In Splendor, optimal decision-making requires understanding both the current game state and strategic relationships between resources cards, and opponents. The 285 engineered features capture three key dimensions: (1) observable game state (gems, visible cards, nobles), (2) player capabilities (resources, reductions, victory points), and (3) derived strategic signals (card affordability, proximity to nobles, relative advantages). By pre-computing these relationships and normalizing all values to [0,1], we simplify the learning task for our MLP baseline, allowing it to focus on pattern recognition rather than complex mathematical reasoning. This approach encodes domain expertise directly into the feature space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "9Ry1HCABBj8H"
      },
      "outputs": [],
      "source": [
        "# Dictionary to store all normalized features\n",
        "normalized_features = {}\n",
        "\n",
        "#Copy of the combined dataframe\n",
        "df = combined_df.copy()\n",
        "features_df = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "tw_eVCp1NFK5"
      },
      "outputs": [],
      "source": [
        "# 1. GLOBAL features for capturing temporal context and available resources on the board ==> 10 features\n",
        "\n",
        "# 1.1 Turn number for temporal context (early/mid/late game) ==> 1 feature\n",
        "normalized_features['turn_number'] = df[\"turn_number\"] / df['turn_number'].max()\n",
        "\n",
        "# 1.2. Gems on board for resource availability ==> 6 features\n",
        "for color in ['white', 'blue', 'green', 'red', 'black', 'gold']:\n",
        "    normalized_features[f'gems_board_{color}'] = df[f'gems_board_{color}'] / df[f'gems_board_{color}'].max()\n",
        "\n",
        "# 1.3. Normalize for remaining cards on deck\n",
        "# Helps to learn about the progress of the game and time the strategies ==> 3 features\n",
        "normalized_features['deck_level1_remaining'] = df['deck_level1_remaining'] / df['deck_level1_remaining'].max()\n",
        "normalized_features['deck_level2_remaining'] = df['deck_level2_remaining'] / df['deck_level2_remaining'].max()\n",
        "normalized_features['deck_level3_remaining'] = df['deck_level3_remaining'] / df['deck_level3_remaining'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "04fDIvpENO4O"
      },
      "outputs": [],
      "source": [
        "# 2. VISIBLE CARDS ==> 12 cards x 7 features (each color) = 84 features\n",
        "# Cards on the board represent immediate purchasing opportunities\n",
        "\n",
        "# 2.1. Normalize for victory points and cost for each color\n",
        "# The maximum for vp across all card is 5\n",
        "# There are 12 cards in total\n",
        "\n",
        "for i in range(12):\n",
        "  normalized_features[f'card{i}_vp'] = df[f'card{i}_vp'] / 5.0\n",
        "  normalized_features[f'card{i}_level'] = df[f'card{i}_level'] / 3.0 # Level (ordinal: 1, 2, 3 → represents difficulty/tier)\n",
        "  for color in ['white', 'blue', 'green', 'red', 'black']:\n",
        "    normalized_features[f'card{i}_cost_{color}'] = df[f'card{i}_cost_{color}'] / df[f'card{i}_cost_{color}'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "02c9lyT2NVJj"
      },
      "outputs": [],
      "source": [
        "#3. NOBLES ==> 5 nobles x 6 features = 30 features\n",
        "# Represent long-term strategic objectives\n",
        "for i in range(5):\n",
        "    # VP (always 3, but normalized for consistency)\n",
        "    normalized_features[f'noble{i}_vp'] = df[f'noble{i}_vp'] / 3.0\n",
        "\n",
        "    # Requirements (reduction bonuses needed)\n",
        "    for color in ['white', 'blue', 'green', 'red', 'black']:\n",
        "        normalized_features[f'noble{i}_req_{color}'] = df[f'noble{i}_req_{color}'] / df[f'noble{i}_req_{color}'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "aMqAUOItNY9F"
      },
      "outputs": [],
      "source": [
        "# 4. PLAYER STATES (2 players × 42 features = 84 features)\n",
        "# Captures resources, reductions, VP, and reserved cards for both players\n",
        "for player_idx in range(2):\n",
        "    # 4.1. Gems (immediate purchasing power)\n",
        "    for color in ['white', 'blue', 'green', 'red', 'black', 'gold']:\n",
        "        normalized_features[f'player{player_idx}_gems_{color}'] = df[f'player{player_idx}_gems_{color}'] / df[f'player{player_idx}_gems_{color}'].max()\n",
        "\n",
        "    # 4.2. Permanent reductions (the \"engine\" - permanent discounts)\n",
        "    for color in ['white', 'blue', 'green', 'red', 'black']:\n",
        "        normalized_features[f'player{player_idx}_reduction_{color}'] = df[f'player{player_idx}_reduction_{color}'] / df[f'player{player_idx}_reduction_{color}'].max()\n",
        "\n",
        "    # 4.3. Victory points (goal is 15)\n",
        "    normalized_features[f'player{player_idx}_vp'] = df[f'player{player_idx}_vp'] / df[f'player{player_idx}_vp'].max()\n",
        "\n",
        "    # 4.4. Position (0 or 1 - already binary)\n",
        "    normalized_features[f'player{player_idx}_position'] = df[f'player{player_idx}_position']\n",
        "\n",
        "    # 4.5. Reserved cards (hidden strategic advantage - max 3 per player)\n",
        "    for reserve_idx in range(3):\n",
        "        normalized_features[f'player{player_idx}_reserved{reserve_idx}_vp'] = df[f'player{player_idx}_reserved{reserve_idx}_vp'] / df[f'player{player_idx}_reserved{reserve_idx}_vp'].max()\n",
        "        normalized_features[f'player{player_idx}_reserved{reserve_idx}_level'] = df[f'player{player_idx}_reserved{reserve_idx}_level'] / 3.0\n",
        "\n",
        "        for color in ['white', 'blue', 'green', 'red', 'black']:\n",
        "            normalized_features[f'player{player_idx}_reserved{reserve_idx}_cost_{color}'] = df[f'player{player_idx}_reserved{reserve_idx}_cost_{color}'] / df[f'player{player_idx}_reserved{reserve_idx}_cost_{color}'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "Cs5TfTy5Neot"
      },
      "outputs": [],
      "source": [
        "# 5. DERIVED STRATEGIC FEATURES\n",
        "# Pre-computed relationships that help the MLP understand strategic situations\n",
        "import numpy as np\n",
        "\n",
        "#5.1 Affordability\n",
        "# Question: \"Can the active player buy this card RIGHT NOW with current resources?\"\n",
        "# Logic: For each card, check if (gems + reductions + gold) >= card cost\n",
        "\n",
        "# extract current_player for fast indexing\n",
        "current_player = df['current_player'].values\n",
        "\n",
        "# Loop through each of the 12 visible cards\n",
        "for card_idx in range(12):\n",
        "\n",
        "    #1.Calculate total gold needed for PLAYER 0 to buy this card\n",
        "    total_gold_p0 = np.zeros(len(df))  # Start with 0 gold needed per row\n",
        "\n",
        "    for color in ['white', 'blue', 'green', 'red', 'black']:\n",
        "        # Get card cost for this color (same for all rows)\n",
        "        cost = df[f'card{card_idx}_cost_{color}'].values\n",
        "\n",
        "        # Calculate what player 0 has available = gems + permanent reductions\n",
        "        available_p0 = (df[f'player0_gems_{color}'].values +\n",
        "                       df[f'player0_reduction_{color}'].values)\n",
        "\n",
        "        # Calculate : how much is missing? (0 if already enough)\n",
        "        shortfall_p0 = np.maximum(0, cost - available_p0)\n",
        "\n",
        "        # Accumulate shortfall across all 5 colors\n",
        "        total_gold_p0 += shortfall_p0\n",
        "\n",
        "    # Check if player 0 has enough gold to cover all shortfalls\n",
        "    can_afford_p0 = (total_gold_p0 <= df['player0_gems_gold'].values).astype(float)\n",
        "\n",
        "    #Same logic for the other player\n",
        "\n",
        "    # 2. Calculate total gold needed for PLAYER 1 to buy this card\n",
        "    total_gold_p1 = np.zeros(len(df))  # Start with 0 gold needed per row\n",
        "\n",
        "    for color in ['white', 'blue', 'green', 'red', 'black']:\n",
        "        # Get card cost for this color\n",
        "        cost = df[f'card{card_idx}_cost_{color}'].values\n",
        "\n",
        "        # Calculate what player 1 has available\n",
        "        available_p1 = (df[f'player1_gems_{color}'].values +\n",
        "                       df[f'player1_reduction_{color}'].values)\n",
        "\n",
        "        # Calculate shortfall for player 1\n",
        "        shortfall_p1 = np.maximum(0, cost - available_p1)\n",
        "\n",
        "        # Accumulate shortfall across all 5 colors\n",
        "        total_gold_p1 += shortfall_p1\n",
        "\n",
        "    # Check if player 1 has enough gold to cover all shortfalls\n",
        "    can_afford_p1 = (total_gold_p1 <= df['player1_gems_gold'].values).astype(float)\n",
        "\n",
        "\n",
        "    # 3. Select the right affordability based on whose turn it is\n",
        "    # For each row: if current_player=0, use can_afford_p0, else use can_afford_p1\n",
        "    normalized_features[f'can_afford_card{card_idx}'] = np.where(\n",
        "        current_player == 0,  # Condition: is it player 0's turn?\n",
        "        can_afford_p0,        # If yes, use player 0's affordability\n",
        "        can_afford_p1         # If no, use player 1's affordability\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "N4mTaHRTSKIZ"
      },
      "outputs": [],
      "source": [
        "# 5.2 Distances to Nobles (25 features: 5 nobles × 5 colors)\n",
        "# How many more reductions needed to attract each noble?\n",
        "\n",
        "current_player = df['current_player'].values\n",
        "\n",
        "# Loop through each of the 5 nobles\n",
        "for noble_idx in range(5):\n",
        "\n",
        "    # Loop through each color requirement\n",
        "    for color in ['white', 'blue', 'green', 'red', 'black']:\n",
        "\n",
        "        # 1.Get noble requirement for this color (same across all rows)\n",
        "        required = df[f'noble{noble_idx}_req_{color}'].values\n",
        "\n",
        "        # 2.Get reductions owned by each player\n",
        "        owned_p0 = df[f'player0_reduction_{color}'].values\n",
        "        owned_p1 = df[f'player1_reduction_{color}'].values\n",
        "\n",
        "        # 3.Calculate distance for each player\n",
        "        # Distance = how many more reductions needed (0 if already satisfied)\n",
        "        distance_p0 = np.maximum(0, required - owned_p0)\n",
        "        distance_p1 = np.maximum(0, required - owned_p1)\n",
        "\n",
        "        # 4.Select based on whose turn it is\n",
        "        # For each row: if current_player=0, use distance_p0, else use distance_p1\n",
        "        distance_active = np.where(\n",
        "            current_player == 0,  # Condition: is it player 0's turn?\n",
        "            distance_p0,          # If yes, use player 0's distance\n",
        "            distance_p1           # If no, use player 1's distance\n",
        "        )\n",
        "\n",
        "        # 5.Normalize by max requirement (4)\n",
        "        normalized_features[f'distance_noble{noble_idx}_{color}'] = distance_active / 4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "cnYl-hUaTB5J"
      },
      "outputs": [],
      "source": [
        "# 5.3 Relative advantages\n",
        "# Compare active player vs opponent on some key metrics\n",
        "# Relative VP\n",
        "\n",
        "# Pre-extract current_player as numpy array for fast indexing\n",
        "current_player = df['current_player'].values\n",
        "\n",
        "# --- F3.1: RELATIVE VICTORY POINTS ---\n",
        "# Who is winning? Positive = active player ahead, Negative = opponent ahead\n",
        "vp_p0 = df['player0_vp'].values\n",
        "vp_p1 = df['player1_vp'].values\n",
        "\n",
        "# Calculate difference: active player VP - opponent VP\n",
        "relative_vp = np.where(\n",
        "    current_player == 0,     # If player 0's turn\n",
        "    vp_p0 - vp_p1,          # Player 0 - Player 1\n",
        "    vp_p1 - vp_p0           # Player 1 - Player 0\n",
        ")\n",
        "normalized_features['relative_vp'] = relative_vp / 15.0  # Normalize by winning VP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "tlHh1ZoSTMW_"
      },
      "outputs": [],
      "source": [
        "# 5.4 RELATIVE GEMS (5 colors)\n",
        "# Who has more gems of each color?\n",
        "for color in ['white', 'blue', 'green', 'red', 'black']:\n",
        "    gems_p0 = df[f'player0_gems_{color}'].values\n",
        "    gems_p1 = df[f'player1_gems_{color}'].values\n",
        "\n",
        "    # Calculate difference: active player gems - opponent gems\n",
        "    relative_gems = np.where(\n",
        "        current_player == 0,     # If player 0's turn\n",
        "        gems_p0 - gems_p1,      # Player 0 - Player 1\n",
        "        gems_p1 - gems_p0       # Player 1 - Player 0\n",
        "    )\n",
        "    normalized_features[f'relative_gems_{color}'] = relative_gems / relative_gems.max() # Normalize by max gems\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "kL1E66AWTT-D"
      },
      "outputs": [],
      "source": [
        "# 5.5 RELATIVE REDUCTIONS (5 colors) ---\n",
        "# Who has a stronger \"engine\" (more permanent bonuses)?\n",
        "for color in ['white', 'blue', 'green', 'red', 'black']:\n",
        "    reduction_p0 = df[f'player0_reduction_{color}'].values\n",
        "    reduction_p1 = df[f'player1_reduction_{color}'].values\n",
        "\n",
        "    # Calculate difference: active player reductions - opponent reductions\n",
        "    relative_reductions = np.where(\n",
        "        current_player == 0,     # If player 0's turn\n",
        "        reduction_p0 - reduction_p1,  # Player 0 - Player 1\n",
        "        reduction_p1 - reduction_p0   # Player 1 - Player 0\n",
        "    )\n",
        "    normalized_features[f'relative_reduction_{color}'] = relative_reductions / relative_reductions.max() # Normalize by typical max\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "iqFNO-kfTdDz"
      },
      "outputs": [],
      "source": [
        "# 5.6 GEM DIVERSITY\n",
        "# How many different gem colors does the active player have?\n",
        "# Get gems for each player and color\n",
        "gems_p0_white = df['player0_gems_white'].values\n",
        "gems_p0_blue = df['player0_gems_blue'].values\n",
        "gems_p0_green = df['player0_gems_green'].values\n",
        "gems_p0_red = df['player0_gems_red'].values\n",
        "gems_p0_black = df['player0_gems_black'].values\n",
        "\n",
        "gems_p1_white = df['player1_gems_white'].values\n",
        "gems_p1_blue = df['player1_gems_blue'].values\n",
        "gems_p1_green = df['player1_gems_green'].values\n",
        "gems_p1_red = df['player1_gems_red'].values\n",
        "gems_p1_black = df['player1_gems_black'].values\n",
        "\n",
        "# Count how many colors each player has (binary: has gems or not)\n",
        "diversity_p0 = ((gems_p0_white > 0).astype(int) +\n",
        "                (gems_p0_blue > 0).astype(int) +\n",
        "                (gems_p0_green > 0).astype(int) +\n",
        "                (gems_p0_red > 0).astype(int) +\n",
        "                (gems_p0_black > 0).astype(int))\n",
        "\n",
        "diversity_p1 = ((gems_p1_white > 0).astype(int) +\n",
        "                (gems_p1_blue > 0).astype(int) +\n",
        "                (gems_p1_green > 0).astype(int) +\n",
        "                (gems_p1_red > 0).astype(int) +\n",
        "                (gems_p1_black > 0).astype(int))\n",
        "\n",
        "# Select based on current player and normalize by max (5 colors)\n",
        "gem_diversity = np.where(\n",
        "    current_player == 0,\n",
        "    diversity_p0,\n",
        "    diversity_p1\n",
        ") / 5.0\n",
        "\n",
        "normalized_features['gem_diversity'] = gem_diversity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "9Ho7h8WKTdzZ"
      },
      "outputs": [],
      "source": [
        "# 5.7 Total gems\n",
        "# How many total gems does the active player have? (approaching 10 = must buy/reserve soon)\n",
        "total_gems_p0 = (gems_p0_white + gems_p0_blue + gems_p0_green +\n",
        "                 gems_p0_red + gems_p0_black + df['player0_gems_gold'].values)\n",
        "\n",
        "total_gems_p1 = (gems_p1_white + gems_p1_blue + gems_p1_green +\n",
        "                 gems_p1_red + gems_p1_black + df['player1_gems_gold'].values)\n",
        "\n",
        "# Select based on current player and normalize by max (10 gems)\n",
        "total_gems = np.where(\n",
        "    current_player == 0,\n",
        "    total_gems_p0,\n",
        "    total_gems_p1\n",
        ") / 10.0\n",
        "\n",
        "normalized_features['total_gems'] = total_gems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "xpejaRN0TjOZ"
      },
      "outputs": [],
      "source": [
        "# 5.8 Total reduction\n",
        "# How powerful is the active player (more reductions = easier to buy cards)\n",
        "total_reductions_p0 = (df['player0_reduction_white'].values +\n",
        "                       df['player0_reduction_blue'].values +\n",
        "                       df['player0_reduction_green'].values +\n",
        "                       df['player0_reduction_red'].values +\n",
        "                       df['player0_reduction_black'].values)\n",
        "\n",
        "total_reductions_p1 = (df['player1_reduction_white'].values +\n",
        "                       df['player1_reduction_blue'].values +\n",
        "                       df['player1_reduction_green'].values +\n",
        "                       df['player1_reduction_red'].values +\n",
        "                       df['player1_reduction_black'].values)\n",
        "\n",
        "# Select based on current player and normalize by theoretical max of 35\n",
        "total_reductions = np.where(\n",
        "    current_player == 0,\n",
        "    total_reductions_p0,\n",
        "    total_reductions_p1\n",
        ") / 24.0\n",
        "\n",
        "normalized_features['total_reductions'] = total_reductions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "ibwiZ_lvLwKZ"
      },
      "outputs": [],
      "source": [
        "#6. Concatenate all features to avoid fragmentation of dataframe\n",
        "# From dictionary to dataframe\n",
        "\n",
        "features_df = pd.DataFrame(normalized_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "ZW12p8N-b2eu"
      },
      "outputs": [],
      "source": [
        "# Remove redundant player0_position and player1_position from the dataframe\n",
        "cols_to_remove = [\"player0_position\", \"player1_position\"]\n",
        "features_df = features_df.drop(columns=cols_to_remove)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "-5fvSJW7cwnb"
      },
      "outputs": [],
      "source": [
        "# Download first 57 rows as CSV to make some manual spotchecks\n",
        "# features_df.head(57).to_csv('first_57_rows2.csv', index=False)\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download('first_57_rows2.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH7IXBmddcF6"
      },
      "source": [
        "#### 2. Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "rpeo2Z6vdbRv"
      },
      "outputs": [],
      "source": [
        "# 2.1 Delete the empty columns in the features_df\n",
        "features_df = features_df.dropna(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRuZfeM0dtsb",
        "outputId": "3b177ad3-f3f8-4aa9-9c3a-d1fe9c20973b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features: 144\n"
          ]
        }
      ],
      "source": [
        "# 2.2 Find the final number of features\n",
        "nb_features = features_df.columns.size\n",
        "print(\"Number of features:\", nb_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "1NXPza4UeDrT"
      },
      "outputs": [],
      "source": [
        "# 2.3 Define the Target Variable (Y): Extract the action the current player took (the label your model will try to predict) from the original combined DataFrame.\n",
        "# Y is action_type in the df\n",
        "Y = df[\"action_type\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPB5e9VggFrg",
        "outputId": "e1324616-a31f-4b6d-a1cf-d3ce1d7f4c36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in feature dataframe: 203568\n",
            "Number of columns in feature dataframe: 144\n",
            "\n",
            "\n",
            "Number of rows in the target column: 203568\n"
          ]
        }
      ],
      "source": [
        "# 2.4 Print shape of target column and feature dataframe\n",
        "rows, cols = features_df.shape\n",
        "\n",
        "print(\"Number of rows in feature dataframe:\", rows)\n",
        "print(\"Number of columns in feature dataframe:\", cols)\n",
        "print('\\n')\n",
        "print(\"Number of rows in the target column:\", Y.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "MjPGzV0GgX_P"
      },
      "outputs": [],
      "source": [
        "# 2.5 Combine the target column with the feature dataframe\n",
        "Y = Y.rename(\"target\")\n",
        "final_df = pd.concat([features_df, Y], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFJHIReIjv6X"
      },
      "source": [
        "#### 3. Split the dataset into train and test dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jwPs91Uj1Si",
        "outputId": "25f65438-0ca6-4abc-c6dd-1e581230c299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape: (142497, 144) (142497,)\n",
            "Validation set shape: (30535, 144) (30535,)\n",
            "Test set shape: (30536, 144) (30536,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Separate features (X) and target (y)\n",
        "X = final_df.drop(columns=[\"target\"])\n",
        "y = final_df[\"target\"]\n",
        "\n",
        "# 2. First split: 70% train, 30% temp (which will become 15% val + 15% test)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3,           # 30% for temp (val + test)\n",
        "    random_state=42,         # reproducibility\n",
        "    stratify=y               # keeps class distribution balanced\n",
        ")\n",
        "\n",
        "# 3. Second split: split the 30% temp into 15% val and 15% test (50-50 split of temp)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp,\n",
        "    test_size=0.5,           # 50% of temp = 15% of total\n",
        "    random_state=42,         # reproducibility\n",
        "    stratify=y_temp          # keeps class distribution balanced\n",
        ")\n",
        "\n",
        "print(\"Train set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
        "print(\"Test set shape:\", X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idPH6HLtkPl6",
        "outputId": "fd70fec0-a67c-462f-9fc6-c54abc465e5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset size: 203568 rows\n",
            "----------------------------------------\n",
            "Training features (X_train) size:   (142497, 144)\n",
            "Validation features (X_val) size:  (30535, 144)\n",
            "Testing features (X_test) size:    (30536, 144)\n",
            "----------------------------------------\n",
            "Training target (y_train) size:    (142497,)\n",
            "Validation target (y_val) size:   (30535,)\n",
            "Testing target (y_test) size:     (30536,)\n",
            "\n",
            "Class distribution in y_train:\n",
            "target\n",
            "build            0.518193\n",
            "take 3 tokens    0.454838\n",
            "take 2 tokens    0.026176\n",
            "reserve          0.000793\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Class distribution in y_val:\n",
            "target\n",
            "build            0.518192\n",
            "take 3 tokens    0.454855\n",
            "take 2 tokens    0.026167\n",
            "reserve          0.000786\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Class distribution in y_test:\n",
            "target\n",
            "build            0.518208\n",
            "take 3 tokens    0.454840\n",
            "take 2 tokens    0.026166\n",
            "reserve          0.000786\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# 3. Print the resulting sizes to verify the split\n",
        "print(f\"Original dataset size: {len(X)} rows\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"Training features (X_train) size:   {X_train.shape}\")\n",
        "print(f\"Validation features (X_val) size:  {X_val.shape}\")\n",
        "print(f\"Testing features (X_test) size:    {X_test.shape}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"Training target (y_train) size:    {y_train.shape}\")\n",
        "print(f\"Validation target (y_val) size:   {y_val.shape}\")\n",
        "print(f\"Testing target (y_test) size:     {y_test.shape}\")\n",
        "\n",
        "# 4. Verify the class balance\n",
        "print(\"\\nClass distribution in y_train:\")\n",
        "print(y_train.value_counts(normalize=True))\n",
        "\n",
        "print(\"\\nClass distribution in y_val:\")\n",
        "print(y_val.value_counts(normalize=True))\n",
        "\n",
        "print(\"\\nClass distribution in y_test:\")\n",
        "print(y_test.value_counts(normalize=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZVIgDwAIY9T"
      },
      "source": [
        "#### 4. Address class imbalance\n",
        ">With reserve at only 0.08%, use class weights in your loss function (inversely proportional to class frequencies) to prevent the model from ignoring this rare but strategically important action."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsh0YaRzLbHY"
      },
      "source": [
        "### 5 . Training the MLP model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "sRmhEPCuLiS8"
      },
      "outputs": [],
      "source": [
        "# Importing the right libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# 1. Convert to PyTorch tensors\n",
        "# Convert features\n",
        "X_train_tensor = torch.FloatTensor(X_train.values)\n",
        "X_val_tensor   = torch.FloatTensor(X_val.values)\n",
        "X_test_tensor  = torch.FloatTensor(X_test.values)\n",
        "\n",
        "# Convert target\n",
        "# Convert target labels (strings) to class indices\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_indices = label_encoder.fit_transform(y_train)   # Fit on train\n",
        "y_val_indices   = label_encoder.transform(y_val)         # Transform validation\n",
        "y_test_indices  = label_encoder.transform(y_test)        # Transform test\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "y_train_tensor = torch.LongTensor(y_train_indices)\n",
        "y_val_tensor   = torch.LongTensor(y_val_indices)\n",
        "y_test_tensor  = torch.LongTensor(y_test_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrdjnU_XMK-0",
        "outputId": "730abff1-0eac-40b7-b616-aa6f911843c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label encoding:\n",
            "  0: build\n",
            "  1: reserve\n",
            "  2: take 2 tokens\n",
            "  3: take 3 tokens\n"
          ]
        }
      ],
      "source": [
        "# 1.1 Verify encoding\n",
        "print(\"Label encoding:\")\n",
        "for idx, label in enumerate(label_encoder.classes_):\n",
        "    print(f\"  {idx}: {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "dgHPfcaVNq1j"
      },
      "outputs": [],
      "source": [
        "# 2. Create TensorDatasets\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset   = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "test_dataset  = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# 3. Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPX19inFNyf4",
        "outputId": "fbe78715-236a-4882-adb6-b6c3ae5a48f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights:\n",
            "  build: 0.48\n",
            "  reserve: 315.26\n",
            "  take 2 tokens: 9.55\n",
            "  take 3 tokens: 0.55\n"
          ]
        }
      ],
      "source": [
        "# 3. Compute the class weights (for imbalanced classes)\n",
        "# This time we do it before training with the right label encoding\n",
        "\n",
        "# Label encoding:\n",
        "#   0: build\n",
        "#   1: reserve\n",
        "#   2: take 2 tokens\n",
        "#   3: take 3 tokens\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "classes = np.array([0, 1, 2, 3])\n",
        "\n",
        "# Compute weights based on training set only\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=classes,\n",
        "    y=y_train_indices\n",
        ")\n",
        "class_weights_tensor = torch.FloatTensor(class_weights)\n",
        "\n",
        "# Move class weights to GPU (for criterion)\n",
        "class_weights_tensor = class_weights_tensor.to(device)\n",
        "\n",
        "print(\"Class weights:\")\n",
        "class_names = ['build', 'reserve', 'take 2 tokens', 'take 3 tokens']\n",
        "for cls_name, weight in zip(class_names, class_weights):\n",
        "    print(f\"  {cls_name}: {weight:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "HVXgsA-6Oxp9"
      },
      "outputs": [],
      "source": [
        "# 4. Define the MLP Model\n",
        "\n",
        "class SplendorMLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden1, hidden2, num_classes, dropout):\n",
        "        super(SplendorMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden1)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden1)\n",
        "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden2)\n",
        "        self.fc3 = nn.Linear(hidden2, num_classes)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)  # No softmax here - CrossEntropyLoss handles it\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check and set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ],
      "metadata": {
        "id": "L5epG-hO6xWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate model\n",
        "model = SplendorMLP(input_dim=144, hidden1=256, hidden2=128, num_classes=4, dropout=0.3)\n",
        "model = model.to(device) # Move model to GPU"
      ],
      "metadata": {
        "id": "-50_-CaI6zdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "dOFXFTIIO0Yx"
      },
      "outputs": [],
      "source": [
        "#5. Define the loss, the optimizr and the scheduler\n",
        "\n",
        "# CrossEntropyLoss is used for multi-class classification.\n",
        "# The 'weight' argument lets us handle class imbalance by giving rare classes more importance.\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n",
        "# Adam optimizer is chosen for its adaptive learning rate and efficiency.\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Scheduler automatically reduces the learning rate when validation loss stops improving.\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku6gzWTvPMIV",
        "outputId": "4f351ebb-10a4-4051-f73d-4e01ae62edbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training...\n",
            "================================================================================\n",
            "Epoch [10/100]\n",
            "  Train Loss: 0.6776, Train Acc: 63.06%\n",
            "  Val Loss:   0.7004, Val Acc:   62.14%\n",
            "Epoch [20/100]\n",
            "  Train Loss: 0.5989, Train Acc: 66.50%\n",
            "  Val Loss:   0.7163, Val Acc:   66.69%\n",
            "\n",
            "Early stopping triggered at epoch 23\n",
            "\n",
            "================================================================================\n",
            "Training complete!\n",
            "Best validation loss: 0.6894\n"
          ]
        }
      ],
      "source": [
        "# 6. Training loop\n",
        "\n",
        "num_epochs = 100\n",
        "best_val_loss = float('inf')  # Track best validation loss\n",
        "patience_counter = 0\n",
        "early_stop_patience = 15\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:  # Iterate through mini-batches\n",
        "        # Move batch to GPU\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track metrics\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        train_total += y_batch.size(0)\n",
        "        train_correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    train_accuracy = 100 * train_correct / train_total\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            # Move batch to GPU\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_total += y_batch.size(0)\n",
        "            val_correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    # Print progress\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "        print(f\"  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}%\")\n",
        "        print(f\"  Val Loss:   {avg_val_loss:.4f}, Val Acc:   {val_accuracy:.2f}%\")\n",
        "\n",
        "    # Early stopping based on validation loss\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), 'best_splendor_model.pth')  # Save best model\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= early_stop_patience:\n",
        "        print(f\"\\nEarly stopping triggered at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Training complete!\")\n",
        "print(f\"Best validation loss: {best_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLrRpZfFViv7",
        "outputId": "6ff5a0b3-87b3-4a2a-fb76-b4e1931854cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "CLASSIFICATION REPORT\n",
            "================================================================================\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        build       0.74      0.74      0.74     15824\n",
            "      reserve       0.03      0.67      0.07        24\n",
            "take 2 tokens       0.12      0.78      0.20       799\n",
            "take 3 tokens       0.77      0.49      0.60     13889\n",
            "\n",
            "     accuracy                           0.63     30536\n",
            "    macro avg       0.41      0.67      0.40     30536\n",
            " weighted avg       0.73      0.63      0.66     30536\n",
            "\n",
            "\n",
            "================================================================================\n",
            "CONFUSION MATRIX\n",
            "================================================================================\n",
            "               build  reserve  take 2 tokens  take 3 tokens\n",
            "build          11714      329           1808           1973\n",
            "reserve            8       16              0              0\n",
            "take 2 tokens     86        0            626             87\n",
            "take 3 tokens   4031      116           2984           6758\n",
            "\n",
            "================================================================================\n",
            "PREDICTION vs ACTUAL DISTRIBUTION\n",
            "================================================================================\n",
            "build                - Predicted: 15839, Actual: 15824\n",
            "reserve              - Predicted:   461, Actual:    24\n",
            "take 2 tokens        - Predicted:  5418, Actual:   799\n",
            "take 3 tokens        - Predicted:  8818, Actual: 13889\n"
          ]
        }
      ],
      "source": [
        "# # Final Test Evaluation - no GPU\n",
        "# PER-CLASS METRICS\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Get predictions\n",
        "model.load_state_dict(torch.load('best_splendor_model.pth'))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "all_predictions = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        # Move batch to GPU\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        outputs = model(X_batch)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Move back to CPU for sklearn\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "        all_targets.extend(y_batch.cpu().numpy())\n",
        "\n",
        "all_predictions = np.array(all_predictions)\n",
        "all_targets = np.array(all_targets)\n",
        "\n",
        "# Get class names\n",
        "class_names = label_encoder.classes_\n",
        "\n",
        "# Print classification report\n",
        "print(\"=\"*80)\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(\"=\"*80)\n",
        "print(classification_report(all_targets, all_predictions, target_names=class_names))\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CONFUSION MATRIX\")\n",
        "print(\"=\"*80)\n",
        "cm = confusion_matrix(all_targets, all_predictions)\n",
        "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "print(cm_df)\n",
        "\n",
        "# Check prediction distribution\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PREDICTION vs ACTUAL DISTRIBUTION\")\n",
        "print(\"=\"*80)\n",
        "for i, cls_name in enumerate(class_names):\n",
        "    pred_count = (all_predictions == i).sum()\n",
        "    actual_count = (all_targets == i).sum()\n",
        "    print(f\"{cls_name:20s} - Predicted: {pred_count:5d}, Actual: {actual_count:5d}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Architecture 1: 256 → 128 → 4, dropout 0.3\n",
        "Accuracy: 63%\n",
        "\n",
        "Macro F1: 0.41 (weighted F1: 0.67)\n",
        "\n",
        "Strengths:\n",
        "\n",
        "Good performance on majority classes (build and take 3 tokens).\n",
        "\n",
        "Recall for rare classes (reserve, take 2 tokens) is surprisingly high (0.83), meaning the model often flags them.\n",
        "\n",
        "Weaknesses:\n",
        "\n",
        "Precision for rare classes is extremely low (0.04 and 0.11), leading to floods of false positives.\n",
        "\n",
        "Over-prediction: e.g., reserve predicted 500 times vs only 24 actual.\n",
        "\n",
        "Interpretation: The larger model memorizes patterns and aggressively predicts minority classes, but without precision. Accuracy looks decent because majority classes dominate."
      ],
      "metadata": {
        "id": "vgC9kbePNgJm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiL-GTXeZ40J"
      },
      "source": [
        "The model achieves 63% accuracy but this metric is misleading due to severe class imbalance issues. While it handles the dominant \"build\" and \"take 3 tokens\" classes reasonably well (77% and 75% precision), it catastrophically fails on minority classes.\n",
        "\n",
        "The most critical failure is \"reserve\" (0.08% of data), which the model over-predicts by 21× (500 predictions vs 24 actual), achieving only 4% precision despite 83% recall. Similarly, \"take 2 tokens\" is over-predicted by 7.3× (5,819 vs 799 actual) with just 11% precision. These extreme over-predictions create floods of false positives that would make the model unusable in practice.\n",
        "\n",
        "The confusion matrix shows systematic errors: 3,164 \"take 3 tokens\" misclassified as \"build\" and 3,111 as \"take 2 tokens.\" The model is simultaneously biased toward common classes when uncertain, yet over-triggers on rare classes. The gap between macro F1 (0.41) and weighted F1 (0.67) confirms that minority class failures are masked by dominant class performance, making the 63% accuracy fundamentally unreliable as a quality metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ67iTIEaa0D"
      },
      "source": [
        "#7. Training loop with MLP (Second attempt)`\n",
        "\n",
        "Key Changes:\n",
        "\n",
        "1. Capped weights to 10.0 - prevents \"reserve\" (315→10) from dominating\n",
        "2. Smaller model (256→256 becomes 128→64) - less overfitting\n",
        "3. Higher dropout (0.3→0.4) - better generalization\n",
        "4. L2 regularization - penalizes large weights\n",
        "5. F1-score for early stopping - better metric for imbalanced data\n",
        "6. Better monitoring - shows F1-score during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ_yAHtmjrBe",
        "outputId": "6af8bb31-b048-48b3-c478-b4ce894844df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: Tesla T4\n",
            "GPU Memory: 15.83 GB\n"
          ]
        }
      ],
      "source": [
        "# Check and set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imFj5mAqbIYq",
        "outputId": "6e51bf3b-52e9-4c6c-9a69-0d760bd6f1e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original vs Capped Class Weights:\n",
            "  build               :    0.48 ->  0.50\n",
            "  reserve             :  315.26 -> 10.00\n",
            "  take 2 tokens       :    9.55 ->  9.55\n",
            "  take 3 tokens       :    0.55 ->  0.55\n"
          ]
        }
      ],
      "source": [
        "# 1. COMPUTE CLASS WEIGHTS - WITH CAPPING TO PREVENT EXTREMES\n",
        "\n",
        "classes = np.array([0, 1, 2, 3])\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=classes,\n",
        "    y=y_train_indices\n",
        ")\n",
        "\n",
        "# CAP THE WEIGHTS: Prevent extreme values from dominating\n",
        "class_weights_capped = np.clip(class_weights, 0.5, 10.0)\n",
        "\n",
        "class_weights_tensor = torch.FloatTensor(class_weights_capped)\n",
        "\n",
        "# Move class weights to GPU (for criterion)\n",
        "class_weights_tensor = class_weights_tensor.to(device)\n",
        "\n",
        "print(\"Original vs Capped Class Weights:\")\n",
        "class_names = label_encoder.classes_\n",
        "for cls_name, orig, capped in zip(class_names, class_weights, class_weights_capped):\n",
        "    print(f\"  {cls_name:20s}: {orig:7.2f} -> {capped:5.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6H9cQeLkADk",
        "outputId": "841b8eb5-8295-4673-982c-9373b914501f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Check device\n",
        "print(class_weights_tensor.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "Xy6cGM0mbT8z"
      },
      "outputs": [],
      "source": [
        "# 3. Smaller model with higher dropout\n",
        "model_v2 = SplendorMLP(input_dim=144, hidden1=128, hidden2=64, num_classes=4, dropout=0.4)\n",
        "# Move model to GPU\n",
        "model_v2 = model_v2.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbmyKsY3bXlu",
        "outputId": "89957839-c2d2-424c-ede7-76798a85577c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model architecture: 144 → 128 → 64 → 4\n",
            "Total parameters: 27,460\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nModel architecture: 144 → 128 → 64 → 4\")\n",
        "print(f\"Total parameters: {sum(p.numel() for p in model_v2.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "TH0WGwZibb8t"
      },
      "outputs": [],
      "source": [
        "#4. Define Loss, Optimizer with L2 Regularization and scheduler\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "optimizer = optim.Adam(model_v2.parameters(), lr=0.001, weight_decay=1e-4)  # L2 regularization\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kiss6dEvaQk2",
        "outputId": "4973d417-bae2-4f94-aa36-b4889684291c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training...\n",
            "================================================================================\n",
            "  ✓ New best Val F1: 0.3732 (saved)\n",
            "  ✓ New best Val F1: 0.3873 (saved)\n",
            "  ✓ New best Val F1: 0.4096 (saved)\n",
            "  ✓ New best Val F1: 0.4512 (saved)\n",
            "Epoch [5/100]\n",
            "  Train Loss: 0.7777, Train Acc: 61.55%\n",
            "  Val Loss:   0.7284, Val Acc:   62.68%, F1: 0.4413\n",
            "  ✓ New best Val F1: 0.4641 (saved)\n",
            "Epoch [10/100]\n",
            "  Train Loss: 0.7150, Train Acc: 62.47%\n",
            "  Val Loss:   0.6802, Val Acc:   61.10%, F1: 0.4068\n",
            "Epoch [15/100]\n",
            "  Train Loss: 0.6889, Train Acc: 63.29%\n",
            "  Val Loss:   0.6496, Val Acc:   62.82%, F1: 0.4637\n",
            "  ✓ New best Val F1: 0.4802 (saved)\n",
            "  ✓ New best Val F1: 0.4892 (saved)\n",
            "Epoch [20/100]\n",
            "  Train Loss: 0.6731, Train Acc: 63.49%\n",
            "  Val Loss:   0.6306, Val Acc:   62.97%, F1: 0.4658\n",
            "  ✓ New best Val F1: 0.5072 (saved)\n",
            "Epoch [25/100]\n",
            "  Train Loss: 0.6556, Train Acc: 64.16%\n",
            "  Val Loss:   0.6287, Val Acc:   65.13%, F1: 0.4855\n",
            "Epoch [30/100]\n",
            "  Train Loss: 0.6561, Train Acc: 63.92%\n",
            "  Val Loss:   0.6271, Val Acc:   63.83%, F1: 0.4671\n",
            "Epoch [35/100]\n",
            "  Train Loss: 0.6475, Train Acc: 64.35%\n",
            "  Val Loss:   0.6327, Val Acc:   63.64%, F1: 0.4697\n",
            "\n",
            "Early stopping at epoch 38\n",
            "\n",
            "================================================================================\n",
            "Training complete!\n",
            "Best validation F1: 0.5072\n",
            "Best validation loss: 0.6299\n"
          ]
        }
      ],
      "source": [
        "# 5. TRAINING LOOP WITH GPU SUPPORT AND VALIDATION SET\n",
        "\n",
        "num_epochs = 100\n",
        "best_val_loss = float('inf')\n",
        "best_val_f1 = 0.0\n",
        "patience_counter = 0\n",
        "early_stop_patience = 15\n",
        "\n",
        "print(\"\\nStarting training...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model_v2.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        # Move batch to GPU\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        outputs = model_v2(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        train_total += y_batch.size(0)\n",
        "        train_correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    train_accuracy = 100 * train_correct / train_total\n",
        "\n",
        "    # Validation phase\n",
        "    model_v2.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    all_val_preds = []\n",
        "    all_val_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            # Move batch to GPU\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            outputs = model_v2(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_total += y_batch.size(0)\n",
        "            val_correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "            # Move predictions back to CPU for sklearn\n",
        "            all_val_preds.extend(predicted.cpu().numpy())\n",
        "            all_val_targets.extend(y_batch.cpu().numpy())\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "\n",
        "    # Calculate macro F1-score\n",
        "    from sklearn.metrics import f1_score\n",
        "    val_f1_macro = f1_score(all_val_targets, all_val_preds, average='macro')\n",
        "\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    # Print progress every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "        print(f\"  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}%\")\n",
        "        print(f\"  Val Loss:   {avg_val_loss:.4f}, Val Acc:   {val_accuracy:.2f}%, F1: {val_f1_macro:.4f}\")\n",
        "\n",
        "    # Early stopping based on validation F1\n",
        "    if val_f1_macro > best_val_f1:\n",
        "        best_val_f1 = val_f1_macro\n",
        "        best_val_loss = avg_val_loss\n",
        "        patience_counter = 0\n",
        "        torch.save(model_v2.state_dict(), 'best_splendor_model_v2.pth')\n",
        "        print(f\"  ✓ New best Val F1: {val_f1_macro:.4f} (saved)\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= early_stop_patience:\n",
        "        print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Training complete!\")\n",
        "print(f\"Best validation F1: {best_val_f1:.4f}\")\n",
        "print(f\"Best validation loss: {best_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final evaluation on test set\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Evaluating on test set...\")\n",
        "model_v2.load_state_dict(torch.load('best_splendor_model_v2.pth'))\n",
        "model_v2.eval()\n",
        "\n",
        "test_loss = 0.0\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "all_test_preds = []\n",
        "all_test_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        outputs = model_v2(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_total += y_batch.size(0)\n",
        "        test_correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "        all_test_preds.extend(predicted.cpu().numpy())\n",
        "        all_test_targets.extend(y_batch.cpu().numpy())\n",
        "\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "\n",
        "# Import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "# Calculate various metrics\n",
        "test_f1_macro = f1_score(all_test_targets, all_test_preds, average='macro')\n",
        "test_f1_weighted = f1_score(all_test_targets, all_test_preds, average='weighted')\n",
        "test_precision_macro = precision_score(all_test_targets, all_test_preds, average='macro')\n",
        "test_recall_macro = recall_score(all_test_targets, all_test_preds, average='macro')\n",
        "\n",
        "print(f\"\\nTest Loss: {avg_test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "print(f\"\\nMacro Metrics:\")\n",
        "print(f\"  Precision: {test_precision_macro:.4f}\")\n",
        "print(f\"  Recall:    {test_recall_macro:.4f}\")\n",
        "print(f\"  F1-Score:  {test_f1_macro:.4f}\")\n",
        "print(f\"\\nWeighted F1-Score: {test_f1_weighted:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(\"=\"*80)\n",
        "class_names = ['build', 'reserve', 'take 2 tokens', 'take 3 tokens']\n",
        "print(classification_report(all_test_targets, all_test_preds,\n",
        "                          target_names=class_names,\n",
        "                          digits=2))\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"=\"*80)\n",
        "print(\"CONFUSION MATRIX\")\n",
        "print(\"=\"*80)\n",
        "cm = confusion_matrix(all_test_targets, all_test_preds)\n",
        "print(f\"{'':>20}\", end='')\n",
        "for name in class_names:\n",
        "    print(f\"{name:>15}\", end='')\n",
        "print()\n",
        "for i, name in enumerate(class_names):\n",
        "    print(f\"{name:>20}\", end='')\n",
        "    for j in range(len(class_names)):\n",
        "        print(f\"{cm[i][j]:>15}\", end='')\n",
        "    print()\n",
        "\n",
        "# Prediction vs Actual distribution\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PREDICTION vs ACTUAL DISTRIBUTION\")\n",
        "print(\"=\"*80)\n",
        "unique_actual, counts_actual = np.unique(all_test_targets, return_counts=True)\n",
        "unique_pred, counts_pred = np.unique(all_test_preds, return_counts=True)\n",
        "\n",
        "# Create dict for easy lookup\n",
        "pred_dict = dict(zip(unique_pred, counts_pred))\n",
        "\n",
        "for i, name in enumerate(class_names):\n",
        "    actual_count = counts_actual[i] if i < len(counts_actual) else 0\n",
        "    pred_count = pred_dict.get(i, 0)\n",
        "    print(f\"{name:>20} - Predicted: {pred_count:>5}, Actual: {actual_count:>5}\")\n",
        "\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1UvgbiKHzqi",
        "outputId": "76902530-de38-47b1-a565-0614f5f58502"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Evaluating on test set...\n",
            "\n",
            "Test Loss: 0.6293\n",
            "Test Accuracy: 63.74%\n",
            "\n",
            "Macro Metrics:\n",
            "  Precision: 0.5114\n",
            "  Recall:    0.6676\n",
            "  F1-Score:  0.5061\n",
            "\n",
            "Weighted F1-Score: 0.6749\n",
            "\n",
            "================================================================================\n",
            "CLASSIFICATION REPORT\n",
            "================================================================================\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        build       0.78      0.74      0.76     15824\n",
            "      reserve       0.39      0.54      0.46        24\n",
            "take 2 tokens       0.11      0.88      0.20       799\n",
            "take 3 tokens       0.76      0.51      0.61     13889\n",
            "\n",
            "     accuracy                           0.64     30536\n",
            "    macro avg       0.51      0.67      0.51     30536\n",
            " weighted avg       0.75      0.64      0.67     30536\n",
            "\n",
            "================================================================================\n",
            "CONFUSION MATRIX\n",
            "================================================================================\n",
            "                              build        reserve  take 2 tokens  take 3 tokens\n",
            "               build          11716              7           1942           2159\n",
            "             reserve             11             13              0              0\n",
            "       take 2 tokens             56              0            705             38\n",
            "       take 3 tokens           3322             13           3524           7030\n",
            "\n",
            "================================================================================\n",
            "PREDICTION vs ACTUAL DISTRIBUTION\n",
            "================================================================================\n",
            "               build - Predicted: 15105, Actual: 15824\n",
            "             reserve - Predicted:    33, Actual:    24\n",
            "       take 2 tokens - Predicted:  6171, Actual:   799\n",
            "       take 3 tokens - Predicted:  9227, Actual: 13889\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Architecture 2 (128→64, dropout 0.4) is slightly better overall with a test accuracy of 63.74% compared to Architecture 1's 63.00%. While both models achieve similar weighted F1 scores (0.67 vs 0.66), Architecture 2 demonstrates significantly better handling of rare actions, particularly \"reserve\" moves where it achieves a precision of 0.39 versus Architecture 1's poor 0.03. Architecture 2 also shows improved recall on \"take 2 tokens\" actions (0.88 vs 0.78), though it trades off slightly worse performance on \"take 3 tokens\" (recall 0.51 vs 0.49). The simpler architecture with fewer parameters reduces overfitting risk while maintaining better balanced performance across all action types, making it more robust for actual gameplay despite having similar macro-level metrics."
      ],
      "metadata": {
        "id": "LwluV-6JNltV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Focal Loss implementation\n",
        "\n",
        "- Focus learning on hard-to-classify examples while being much less aggressive than inverse frequency weighting, preventing the massive overprediction. It avoids exploding gradients and massive overprediction of rare classes.\n",
        "\n",
        "- Oversampling for only the two minority classes (reserve and take 2 tokens) by duplicating them 3-5x in the training set. This gives the model more exposure to rare patterns without distorting the distribution too much."
      ],
      "metadata": {
        "id": "CO45gH0WOKqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Define Focal Loss class and calculate effective class weights\n",
        "# Focal Loss modifies CrossEntropyLoss by adding a focusing term\n",
        "\n",
        "import torch.nn.functional as F\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=1.5, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        return focal_loss"
      ],
      "metadata": {
        "id": "lFKsbwJJRGHx"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Oversample minority classes (reserve 5x, take 2 tokens 3x) to give the model more exposure without extreme weight changes\n",
        "def get_effective_weights(class_counts, beta=0.999):\n",
        "    effective_num = 1.0 - np.power(beta, class_counts)\n",
        "    weights = (1.0 - beta) / effective_num\n",
        "    weights = weights / weights.sum() * len(weights)\n",
        "    return weights\n",
        "\n",
        "# Get counts for each class using your y_train_indices\n",
        "class_counts = np.array([\n",
        "    (y_train_indices == 0).sum(),  # build\n",
        "    (y_train_indices == 1).sum(),  # reserve\n",
        "    (y_train_indices == 2).sum(),  # take 2 tokens\n",
        "    (y_train_indices == 3).sum()   # take 3 tokens\n",
        "])"
      ],
      "metadata": {
        "id": "p7asBFh4SF-9"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Class counts in training set:\")\n",
        "for i, label in enumerate(label_encoder.classes_):\n",
        "    print(f\"  {i}: {label:20} {class_counts[i]:6d} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bU0_vosSdox",
        "outputId": "b9704e4a-9c45-46b7-fe16-0c76207c290c"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts in training set:\n",
            "  0: build                 73841 samples\n",
            "  1: reserve                 113 samples\n",
            "  2: take 2 tokens          3730 samples\n",
            "  3: take 3 tokens         64813 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate weights with beta=0.999\n",
        "class_weights = get_effective_weights(class_counts, beta=0.999)\n",
        "class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
        "\n",
        "print(\"\\nClass weights (effective number method):\")\n",
        "for i, label in enumerate(label_encoder.classes_):\n",
        "    print(f\"  {i}: {label:20} weight: {class_weights[i]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9v004DRTjJw",
        "outputId": "77d6c381-3002-43b9-918a-bffd9b7b011f"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class weights (effective number method):\n",
            "  0: build                weight: 0.3231\n",
            "  1: reserve              weight: 3.0227\n",
            "  2: take 2 tokens        weight: 0.3311\n",
            "  3: take 3 tokens        weight: 0.3231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Oversample Minority Classes"
      ],
      "metadata": {
        "id": "k8It9UNpUqFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tensors back to numpy for oversampling\n",
        "X_train_np = X_train_tensor.cpu().numpy()\n",
        "y_train_np = y_train_tensor.cpu().numpy()\n",
        "\n",
        "X_train_oversampled = X_train_np.copy()\n",
        "y_train_oversampled = y_train_np.copy()"
      ],
      "metadata": {
        "id": "PetEpLEuUmfg"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Oversample reserve class (class 1) - duplicate 5x\n",
        "reserve_indices = np.where(y_train_np == 1)[0]\n",
        "print(f\"Found {len(reserve_indices)} reserve samples, duplicating 5x...\")\n",
        "for _ in range(4):  # 4 more times = 5x total\n",
        "    X_train_oversampled = np.vstack([X_train_oversampled, X_train_np[reserve_indices]])\n",
        "    y_train_oversampled = np.concatenate([y_train_oversampled, y_train_np[reserve_indices]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUhhlnjkUvEz",
        "outputId": "c8fd4a86-8479-439d-c86a-3e2fcfe9f335"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 113 reserve samples, duplicating 5x...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Oversample take 2 tokens (class 2) - duplicate 3x\n",
        "take2_indices = np.where(y_train_np == 2)[0]\n",
        "print(f\"Found {len(take2_indices)} take 2 tokens samples, duplicating 3x...\")\n",
        "for _ in range(2):  # 2 more times = 3x total\n",
        "    X_train_oversampled = np.vstack([X_train_oversampled, X_train_np[take2_indices]])\n",
        "    y_train_oversampled = np.concatenate([y_train_oversampled, y_train_np[take2_indices]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSzHQ53QUx0R",
        "outputId": "008e69a8-4d52-470d-c961-7d71bf48eb01"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3730 take 2 tokens samples, duplicating 3x...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nOriginal training set: {len(y_train_np)} samples\")\n",
        "print(f\"Oversampled training set: {len(y_train_oversampled)} samples\")\n",
        "print(f\"Increase: {len(y_train_oversampled) - len(y_train_np)} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXAPkbNsU2Bx",
        "outputId": "8fbea5b2-d178-4d9d-9aef-c7d14b8ae948"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original training set: 142497 samples\n",
            "Oversampled training set: 150409 samples\n",
            "Increase: 7912 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nNew class distribution:\")\n",
        "for i, label in enumerate(label_encoder.classes_):\n",
        "    count = (y_train_oversampled == i).sum()\n",
        "    pct = 100 * count / len(y_train_oversampled)\n",
        "    print(f\"  {i}: {label:20} {count:6d} ({pct:5.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BnOM4P2U9em",
        "outputId": "325f3581-bb70-42f6-c6ba-59f1daeb75a5"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New class distribution:\n",
            "  0: build                 73841 (49.09%)\n",
            "  1: reserve                 565 ( 0.38%)\n",
            "  2: take 2 tokens         11190 ( 7.44%)\n",
            "  3: take 3 tokens         64813 (43.09%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new dataset with oversampled data\n",
        "train_dataset_oversampled = TensorDataset(\n",
        "    torch.FloatTensor(X_train_oversampled),\n",
        "    torch.LongTensor(y_train_oversampled)\n",
        ")\n",
        "\n",
        "train_loader_oversampled = DataLoader(\n",
        "    train_dataset_oversampled,\n",
        "    batch_size=256,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "print(f\"\\nNew train loader created with {len(train_loader_oversampled)} batches\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRombUbsVTy3",
        "outputId": "d306e9ad-2db7-4f1a-941a-d264184f464d"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New train loader created with 588 batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Model with Focal Loss"
      ],
      "metadata": {
        "id": "HHPLst1bV7HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate model with my architecture\n",
        "model_focal = SplendorMLP(\n",
        "    input_dim=144,\n",
        "    hidden1=128,\n",
        "    hidden2=64,\n",
        "    num_classes=4,\n",
        "    dropout=0.4\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "KHC-EySCVVpd"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Focal Loss with gamma=1.5 and class weights\n",
        "criterion_focal = FocalLoss(alpha=class_weights_tensor, gamma=1.5)"
      ],
      "metadata": {
        "id": "NdU0Xa2VWEaP"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer\n",
        "optimizer_focal = optim.AdamW(\n",
        "    model_focal.parameters(),\n",
        "    lr=0.001,\n",
        "    weight_decay=0.01\n",
        ")"
      ],
      "metadata": {
        "id": "8SZhwQ_nWFUp"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate scheduler\n",
        "scheduler_focal = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer_focal,\n",
        "    mode='max',\n",
        "    factor=0.5,\n",
        "    patience=5\n",
        ")"
      ],
      "metadata": {
        "id": "hjOo6Z2uWPIu"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model initialized with Focal Loss\")\n",
        "print(f\"  Architecture: 144 -> 128 -> 64 -> 4\")\n",
        "print(f\"  Gamma: 1.5\")\n",
        "print(f\"  Dropout: 0.4\")\n",
        "print(f\"  Using oversampled training data: {len(y_train_oversampled):,} samples\")\n",
        "print(f\"  Model parameters: {sum(p.numel() for p in model_focal.parameters()):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-i_5A5pWSAA",
        "outputId": "357550b3-bf7c-4caa-dc91-2c0040921274"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model initialized with Focal Loss\n",
            "  Architecture: 144 -> 128 -> 64 -> 4\n",
            "  Gamma: 1.5\n",
            "  Dropout: 0.4\n",
            "  Using oversampled training data: 150,409 samples\n",
            "  Model parameters: 27,460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop with validation set"
      ],
      "metadata": {
        "id": "SaAz0T9IWusv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "#Training Loop with Focal Loss (GPU)\n",
        "# ============================================================================\n",
        "num_epochs = 50\n",
        "best_val_f1 = 0.0\n",
        "patience_counter = 0\n",
        "early_stop_patience = 20\n",
        "\n",
        "train_losses = []\n",
        "val_f1_scores = []\n",
        "val_losses = []\n",
        "\n",
        "print(\"Starting training...\")\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"Epochs: {num_epochs}\")\n",
        "print(f\"Batch size: 256\")\n",
        "print(f\"Early stopping patience: {early_stop_patience}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # ==================== Training Phase ====================\n",
        "    model_focal.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader_oversampled:\n",
        "        # Move to GPU\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer_focal.zero_grad()\n",
        "        outputs = model_focal(X_batch)\n",
        "        loss = criterion_focal(outputs, y_batch)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping to prevent exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model_focal.parameters(), max_norm=1.0)\n",
        "\n",
        "        # Update weights\n",
        "        optimizer_focal.step()\n",
        "\n",
        "        # Track metrics\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        train_total += y_batch.size(0)\n",
        "        train_correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader_oversampled)\n",
        "    train_accuracy = 100 * train_correct / train_total\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # ==================== Validation Phase ====================\n",
        "    model_focal.eval()\n",
        "    val_loss = 0.0\n",
        "    val_preds = []\n",
        "    val_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            # Move to GPU\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model_focal(X_batch)\n",
        "            loss = criterion_focal(outputs, y_batch)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            # Store predictions for metrics\n",
        "            val_preds.extend(predicted.cpu().numpy())\n",
        "            val_targets.extend(y_batch.cpu().numpy())\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "\n",
        "    # Calculate metrics\n",
        "    from sklearn.metrics import f1_score, accuracy_score\n",
        "    val_f1_macro = f1_score(val_targets, val_preds, average='macro')\n",
        "    val_f1_weighted = f1_score(val_targets, val_preds, average='weighted')\n",
        "    val_accuracy = 100 * accuracy_score(val_targets, val_preds)\n",
        "    val_f1_scores.append(val_f1_macro)\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler_focal.step(val_f1_macro)\n",
        "    current_lr = optimizer_focal.param_groups[0]['lr']\n",
        "\n",
        "    # Print progress\n",
        "    print(f\"Epoch {epoch+1:2d}/{num_epochs} | \"\n",
        "          f\"Train Loss: {avg_train_loss:.4f} | \"\n",
        "          f\"Train Acc: {train_accuracy:.2f}% | \"\n",
        "          f\"Val Loss: {avg_val_loss:.4f} | \"\n",
        "          f\"Val Acc: {val_accuracy:.2f}% | \"\n",
        "          f\"Val F1 (macro): {val_f1_macro:.4f} | \"\n",
        "          f\"Val F1 (weighted): {val_f1_weighted:.4f} | \"\n",
        "          f\"LR: {current_lr:.6f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_f1_macro > best_val_f1:\n",
        "        best_val_f1 = val_f1_macro\n",
        "        torch.save(model_focal.state_dict(), 'best_splendor_focal_model.pth')\n",
        "        patience_counter = 0\n",
        "        print(f\"  ✓ New best model saved! (F1: {best_val_f1:.4f})\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stop_patience:\n",
        "            print(f\"\\nEarly stopping triggered at epoch {epoch+1}\")\n",
        "            print(f\"Best validation F1: {best_val_f1:.4f}\")\n",
        "            break\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Training complete!\")\n",
        "print(f\"Best validation F1 (macro): {best_val_f1:.4f}\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl9ud2t5WV5z",
        "outputId": "c193af41-6135-464a-f0bd-d2e235f8dc0d"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Device: cuda\n",
            "Epochs: 50\n",
            "Batch size: 256\n",
            "Early stopping patience: 20\n",
            "================================================================================\n",
            "Epoch  1/50 | Train Loss: 0.0534 | Train Acc: 62.40% | Val Loss: 0.0345 | Val Acc: 68.89% | Val F1 (macro): 0.3617 | Val F1 (weighted): 0.6856 | LR: 0.001000\n",
            "  ✓ New best model saved! (F1: 0.3617)\n",
            "Epoch  2/50 | Train Loss: 0.0401 | Train Acc: 65.66% | Val Loss: 0.0311 | Val Acc: 70.42% | Val F1 (macro): 0.3993 | Val F1 (weighted): 0.6962 | LR: 0.001000\n",
            "  ✓ New best model saved! (F1: 0.3993)\n",
            "Epoch  3/50 | Train Loss: 0.0366 | Train Acc: 66.43% | Val Loss: 0.0302 | Val Acc: 70.66% | Val F1 (macro): 0.4363 | Val F1 (weighted): 0.7022 | LR: 0.001000\n",
            "  ✓ New best model saved! (F1: 0.4363)\n",
            "Epoch  4/50 | Train Loss: 0.0348 | Train Acc: 66.88% | Val Loss: 0.0306 | Val Acc: 71.60% | Val F1 (macro): 0.4062 | Val F1 (weighted): 0.7040 | LR: 0.001000\n",
            "Epoch  5/50 | Train Loss: 0.0337 | Train Acc: 66.95% | Val Loss: 0.0298 | Val Acc: 71.20% | Val F1 (macro): 0.4128 | Val F1 (weighted): 0.7017 | LR: 0.001000\n",
            "Epoch  6/50 | Train Loss: 0.0326 | Train Acc: 67.03% | Val Loss: 0.0290 | Val Acc: 71.62% | Val F1 (macro): 0.4007 | Val F1 (weighted): 0.7031 | LR: 0.001000\n",
            "Epoch  7/50 | Train Loss: 0.0316 | Train Acc: 67.28% | Val Loss: 0.0289 | Val Acc: 71.78% | Val F1 (macro): 0.4040 | Val F1 (weighted): 0.7046 | LR: 0.001000\n",
            "Epoch  8/50 | Train Loss: 0.0309 | Train Acc: 67.44% | Val Loss: 0.0290 | Val Acc: 70.88% | Val F1 (macro): 0.4644 | Val F1 (weighted): 0.7028 | LR: 0.001000\n",
            "  ✓ New best model saved! (F1: 0.4644)\n",
            "Epoch  9/50 | Train Loss: 0.0306 | Train Acc: 67.43% | Val Loss: 0.0285 | Val Acc: 71.24% | Val F1 (macro): 0.4099 | Val F1 (weighted): 0.7005 | LR: 0.001000\n",
            "Epoch 10/50 | Train Loss: 0.0304 | Train Acc: 67.64% | Val Loss: 0.0307 | Val Acc: 71.68% | Val F1 (macro): 0.4615 | Val F1 (weighted): 0.7092 | LR: 0.001000\n",
            "Epoch 11/50 | Train Loss: 0.0297 | Train Acc: 67.62% | Val Loss: 0.0304 | Val Acc: 71.58% | Val F1 (macro): 0.4043 | Val F1 (weighted): 0.6983 | LR: 0.001000\n",
            "Epoch 12/50 | Train Loss: 0.0292 | Train Acc: 67.87% | Val Loss: 0.0314 | Val Acc: 71.58% | Val F1 (macro): 0.4677 | Val F1 (weighted): 0.7079 | LR: 0.001000\n",
            "  ✓ New best model saved! (F1: 0.4677)\n",
            "Epoch 13/50 | Train Loss: 0.0290 | Train Acc: 67.82% | Val Loss: 0.0315 | Val Acc: 71.59% | Val F1 (macro): 0.4689 | Val F1 (weighted): 0.7084 | LR: 0.001000\n",
            "  ✓ New best model saved! (F1: 0.4689)\n",
            "Epoch 14/50 | Train Loss: 0.0286 | Train Acc: 67.98% | Val Loss: 0.0301 | Val Acc: 71.91% | Val F1 (macro): 0.4014 | Val F1 (weighted): 0.7036 | LR: 0.001000\n",
            "Epoch 15/50 | Train Loss: 0.0282 | Train Acc: 68.04% | Val Loss: 0.0316 | Val Acc: 72.72% | Val F1 (macro): 0.4174 | Val F1 (weighted): 0.7137 | LR: 0.001000\n",
            "Epoch 16/50 | Train Loss: 0.0280 | Train Acc: 68.20% | Val Loss: 0.0313 | Val Acc: 72.99% | Val F1 (macro): 0.4221 | Val F1 (weighted): 0.7154 | LR: 0.001000\n",
            "Epoch 17/50 | Train Loss: 0.0274 | Train Acc: 68.47% | Val Loss: 0.0319 | Val Acc: 71.20% | Val F1 (macro): 0.4698 | Val F1 (weighted): 0.7051 | LR: 0.001000\n",
            "  ✓ New best model saved! (F1: 0.4698)\n",
            "Epoch 18/50 | Train Loss: 0.0271 | Train Acc: 68.49% | Val Loss: 0.0289 | Val Acc: 73.13% | Val F1 (macro): 0.4131 | Val F1 (weighted): 0.7157 | LR: 0.001000\n",
            "Epoch 19/50 | Train Loss: 0.0271 | Train Acc: 68.50% | Val Loss: 0.0310 | Val Acc: 72.78% | Val F1 (macro): 0.4425 | Val F1 (weighted): 0.7159 | LR: 0.001000\n",
            "Epoch 20/50 | Train Loss: 0.0268 | Train Acc: 68.63% | Val Loss: 0.0294 | Val Acc: 72.49% | Val F1 (macro): 0.4708 | Val F1 (weighted): 0.7158 | LR: 0.001000\n",
            "  ✓ New best model saved! (F1: 0.4708)\n",
            "Epoch 21/50 | Train Loss: 0.0264 | Train Acc: 68.77% | Val Loss: 0.0291 | Val Acc: 73.13% | Val F1 (macro): 0.4931 | Val F1 (weighted): 0.7242 | LR: 0.001000\n",
            "  ✓ New best model saved! (F1: 0.4931)\n",
            "Epoch 22/50 | Train Loss: 0.0266 | Train Acc: 68.81% | Val Loss: 0.0298 | Val Acc: 72.62% | Val F1 (macro): 0.4713 | Val F1 (weighted): 0.7203 | LR: 0.001000\n",
            "Epoch 23/50 | Train Loss: 0.0262 | Train Acc: 69.11% | Val Loss: 0.0304 | Val Acc: 73.88% | Val F1 (macro): 0.4515 | Val F1 (weighted): 0.7291 | LR: 0.001000\n",
            "Epoch 24/50 | Train Loss: 0.0259 | Train Acc: 69.10% | Val Loss: 0.0296 | Val Acc: 73.65% | Val F1 (macro): 0.4440 | Val F1 (weighted): 0.7260 | LR: 0.001000\n",
            "Epoch 25/50 | Train Loss: 0.0258 | Train Acc: 69.16% | Val Loss: 0.0319 | Val Acc: 73.91% | Val F1 (macro): 0.4444 | Val F1 (weighted): 0.7275 | LR: 0.001000\n",
            "Epoch 26/50 | Train Loss: 0.0256 | Train Acc: 69.12% | Val Loss: 0.0322 | Val Acc: 74.11% | Val F1 (macro): 0.4275 | Val F1 (weighted): 0.7300 | LR: 0.001000\n",
            "Epoch 27/50 | Train Loss: 0.0252 | Train Acc: 69.16% | Val Loss: 0.0327 | Val Acc: 73.87% | Val F1 (macro): 0.4575 | Val F1 (weighted): 0.7289 | LR: 0.000500\n",
            "Epoch 28/50 | Train Loss: 0.0248 | Train Acc: 69.53% | Val Loss: 0.0329 | Val Acc: 73.34% | Val F1 (macro): 0.4890 | Val F1 (weighted): 0.7295 | LR: 0.000500\n",
            "Epoch 29/50 | Train Loss: 0.0245 | Train Acc: 69.66% | Val Loss: 0.0362 | Val Acc: 74.63% | Val F1 (macro): 0.4429 | Val F1 (weighted): 0.7347 | LR: 0.000500\n",
            "Epoch 30/50 | Train Loss: 0.0243 | Train Acc: 69.77% | Val Loss: 0.0363 | Val Acc: 73.63% | Val F1 (macro): 0.4888 | Val F1 (weighted): 0.7316 | LR: 0.000500\n",
            "Epoch 31/50 | Train Loss: 0.0240 | Train Acc: 69.92% | Val Loss: 0.0356 | Val Acc: 73.89% | Val F1 (macro): 0.4858 | Val F1 (weighted): 0.7324 | LR: 0.000500\n",
            "Epoch 32/50 | Train Loss: 0.0242 | Train Acc: 69.91% | Val Loss: 0.0347 | Val Acc: 74.44% | Val F1 (macro): 0.4460 | Val F1 (weighted): 0.7325 | LR: 0.000500\n",
            "Epoch 33/50 | Train Loss: 0.0240 | Train Acc: 70.04% | Val Loss: 0.0350 | Val Acc: 73.41% | Val F1 (macro): 0.5012 | Val F1 (weighted): 0.7298 | LR: 0.000500\n",
            "  ✓ New best model saved! (F1: 0.5012)\n",
            "Epoch 34/50 | Train Loss: 0.0238 | Train Acc: 70.10% | Val Loss: 0.0351 | Val Acc: 74.71% | Val F1 (macro): 0.4690 | Val F1 (weighted): 0.7390 | LR: 0.000500\n",
            "Epoch 35/50 | Train Loss: 0.0236 | Train Acc: 70.14% | Val Loss: 0.0376 | Val Acc: 73.23% | Val F1 (macro): 0.4982 | Val F1 (weighted): 0.7274 | LR: 0.000500\n",
            "Epoch 36/50 | Train Loss: 0.0236 | Train Acc: 70.22% | Val Loss: 0.0367 | Val Acc: 73.01% | Val F1 (macro): 0.4906 | Val F1 (weighted): 0.7266 | LR: 0.000500\n",
            "Epoch 37/50 | Train Loss: 0.0234 | Train Acc: 70.19% | Val Loss: 0.0381 | Val Acc: 74.57% | Val F1 (macro): 0.4599 | Val F1 (weighted): 0.7389 | LR: 0.000500\n",
            "Epoch 38/50 | Train Loss: 0.0236 | Train Acc: 70.09% | Val Loss: 0.0375 | Val Acc: 73.91% | Val F1 (macro): 0.4698 | Val F1 (weighted): 0.7305 | LR: 0.000500\n",
            "Epoch 39/50 | Train Loss: 0.0234 | Train Acc: 70.05% | Val Loss: 0.0383 | Val Acc: 74.80% | Val F1 (macro): 0.4650 | Val F1 (weighted): 0.7379 | LR: 0.000250\n",
            "Epoch 40/50 | Train Loss: 0.0232 | Train Acc: 70.41% | Val Loss: 0.0401 | Val Acc: 73.57% | Val F1 (macro): 0.5197 | Val F1 (weighted): 0.7336 | LR: 0.000250\n",
            "  ✓ New best model saved! (F1: 0.5197)\n",
            "Epoch 41/50 | Train Loss: 0.0229 | Train Acc: 70.50% | Val Loss: 0.0397 | Val Acc: 74.72% | Val F1 (macro): 0.4773 | Val F1 (weighted): 0.7379 | LR: 0.000250\n",
            "Epoch 42/50 | Train Loss: 0.0231 | Train Acc: 70.34% | Val Loss: 0.0392 | Val Acc: 74.64% | Val F1 (macro): 0.4754 | Val F1 (weighted): 0.7389 | LR: 0.000250\n",
            "Epoch 43/50 | Train Loss: 0.0231 | Train Acc: 70.42% | Val Loss: 0.0402 | Val Acc: 73.77% | Val F1 (macro): 0.5084 | Val F1 (weighted): 0.7349 | LR: 0.000250\n",
            "Epoch 44/50 | Train Loss: 0.0229 | Train Acc: 70.48% | Val Loss: 0.0407 | Val Acc: 73.78% | Val F1 (macro): 0.5020 | Val F1 (weighted): 0.7344 | LR: 0.000250\n",
            "Epoch 45/50 | Train Loss: 0.0227 | Train Acc: 70.58% | Val Loss: 0.0399 | Val Acc: 74.13% | Val F1 (macro): 0.4858 | Val F1 (weighted): 0.7352 | LR: 0.000250\n",
            "Epoch 46/50 | Train Loss: 0.0226 | Train Acc: 70.58% | Val Loss: 0.0403 | Val Acc: 74.70% | Val F1 (macro): 0.4584 | Val F1 (weighted): 0.7407 | LR: 0.000125\n",
            "Epoch 47/50 | Train Loss: 0.0226 | Train Acc: 70.54% | Val Loss: 0.0417 | Val Acc: 73.94% | Val F1 (macro): 0.4774 | Val F1 (weighted): 0.7326 | LR: 0.000125\n",
            "Epoch 48/50 | Train Loss: 0.0226 | Train Acc: 70.63% | Val Loss: 0.0411 | Val Acc: 74.45% | Val F1 (macro): 0.4965 | Val F1 (weighted): 0.7392 | LR: 0.000125\n",
            "Epoch 49/50 | Train Loss: 0.0225 | Train Acc: 70.67% | Val Loss: 0.0414 | Val Acc: 74.69% | Val F1 (macro): 0.4557 | Val F1 (weighted): 0.7385 | LR: 0.000125\n",
            "Epoch 50/50 | Train Loss: 0.0224 | Train Acc: 70.87% | Val Loss: 0.0417 | Val Acc: 73.75% | Val F1 (macro): 0.4865 | Val F1 (weighted): 0.7355 | LR: 0.000125\n",
            "\n",
            "================================================================================\n",
            "Training complete!\n",
            "Best validation F1 (macro): 0.5197\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Set Evaluation"
      ],
      "metadata": {
        "id": "Vq91FTzMYh6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model\n",
        "model_focal.load_state_dict(torch.load('best_splendor_focal_model.pth'))\n",
        "model_focal.eval()\n",
        "\n",
        "# Evaluation\n",
        "test_loss = 0.0\n",
        "test_preds = []\n",
        "test_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        # Move to GPU\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model_focal(X_batch)\n",
        "        loss = criterion_focal(outputs, y_batch)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Store predictions\n",
        "        test_preds.extend(predicted.cpu().numpy())\n",
        "        test_targets.extend(y_batch.cpu().numpy())\n",
        "\n",
        "# Calculate metrics\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "test_accuracy = 100 * accuracy_score(test_targets, test_preds)\n",
        "test_f1_macro = f1_score(test_targets, test_preds, average='macro')\n",
        "test_f1_weighted = f1_score(test_targets, test_preds, average='weighted')\n",
        "test_precision_macro = precision_score(test_targets, test_preds, average='macro')\n",
        "test_recall_macro = recall_score(test_targets, test_preds, average='macro')\n",
        "\n",
        "print(f\"\\nTest Loss: {avg_test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "print(f\"\\nMacro Metrics:\")\n",
        "print(f\"  Precision: {test_precision_macro:.4f}\")\n",
        "print(f\"  Recall:    {test_recall_macro:.4f}\")\n",
        "print(f\"  F1-Score:  {test_f1_macro:.4f}\")\n",
        "print(f\"\\nWeighted F1-Score: {test_f1_weighted:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eO734AdYfG1",
        "outputId": "d700225d-d6c1-4ba5-eaea-4f257d267fb7"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Loss: 0.0445\n",
            "Test Accuracy: 73.62%\n",
            "\n",
            "Macro Metrics:\n",
            "  Precision: 0.4844\n",
            "  Recall:    0.4951\n",
            "  F1-Score:  0.4858\n",
            "\n",
            "Weighted F1-Score: 0.7341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Set Detailed Analysis\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CLASSIFICATION REPORT (TEST SET)\")\n",
        "print(\"=\"*80)\n",
        "print(classification_report(\n",
        "    test_targets,\n",
        "    test_preds,\n",
        "    target_names=label_encoder.classes_,\n",
        "    digits=4\n",
        "))\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"CONFUSION MATRIX (TEST SET)\")\n",
        "print(\"=\"*80)\n",
        "cm = confusion_matrix(test_targets, test_preds)\n",
        "print(f\"{'':>20}\", end='')\n",
        "for label in label_encoder.classes_:\n",
        "    print(f\"{label:>15}\", end='')\n",
        "print()\n",
        "for i, label in enumerate(label_encoder.classes_):\n",
        "    print(f\"{label:>20}\", end='')\n",
        "    for j in range(len(label_encoder.classes_)):\n",
        "        print(f\"{cm[i][j]:>15}\", end='')\n",
        "    print()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PREDICTION vs ACTUAL DISTRIBUTION (TEST SET)\")\n",
        "print(\"=\"*80)\n",
        "unique_actual, counts_actual = np.unique(test_targets, return_counts=True)\n",
        "unique_pred, counts_pred = np.unique(test_preds, return_counts=True)\n",
        "\n",
        "pred_dict = dict(zip(unique_pred, counts_pred))\n",
        "\n",
        "for i, label in enumerate(label_encoder.classes_):\n",
        "    actual_count = counts_actual[i] if i < len(counts_actual) else 0\n",
        "    pred_count = pred_dict.get(i, 0)\n",
        "    ratio = pred_count / actual_count if actual_count > 0 else 0\n",
        "    print(f\"{label:>20} | Predicted: {pred_count:>5} | Actual: {actual_count:>5} | Ratio: {ratio:.2f}x\")\n",
        "\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StFUNgbjY14h",
        "outputId": "f8e861cc-198c-4225-d438-cc8673a0e820"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "CLASSIFICATION REPORT (TEST SET)\n",
            "================================================================================\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        build     0.7415    0.8503    0.7922     15824\n",
            "      reserve     0.1667    0.1667    0.1667        24\n",
            "take 2 tokens     0.2565    0.3329    0.2898       799\n",
            "take 3 tokens     0.7728    0.6304    0.6944     13889\n",
            "\n",
            "     accuracy                         0.7362     30536\n",
            "    macro avg     0.4844    0.4951    0.4858     30536\n",
            " weighted avg     0.7426    0.7362    0.7341     30536\n",
            "\n",
            "================================================================================\n",
            "CONFUSION MATRIX (TEST SET)\n",
            "================================================================================\n",
            "                              build        reserve  take 2 tokens  take 3 tokens\n",
            "               build          13455              5            118           2246\n",
            "             reserve             18              4              0              2\n",
            "       take 2 tokens            207              0            266            326\n",
            "       take 3 tokens           4465             15            653           8756\n",
            "\n",
            "================================================================================\n",
            "PREDICTION vs ACTUAL DISTRIBUTION (TEST SET)\n",
            "================================================================================\n",
            "               build | Predicted: 18145 | Actual: 15824 | Ratio: 1.15x\n",
            "             reserve | Predicted:    24 | Actual:    24 | Ratio: 1.00x\n",
            "       take 2 tokens | Predicted:  1037 | Actual:   799 | Ratio: 1.30x\n",
            "       take 3 tokens | Predicted: 11330 | Actual: 13889 | Ratio: 0.82x\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Focal Loss + Oversampling achieved target performance\n",
        "\n",
        "..."
      ],
      "metadata": {
        "id": "nKcYn5p5Z9Lk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning the best model\n",
        "\n",
        "- loss function tuning : adjusting the focal loss γ (between 1.5–2.0) and refining class weights based on effective sample counts might provide the most immediate gains in minority class performance."
      ],
      "metadata": {
        "id": "1Cf4sPqpoilS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. CLASS WEIGHT CALCULATION METHODS\n",
        "\n",
        "The following function calculates class weights using the “effective number of samples” method.\n",
        "\n",
        "The idea: classes with fewer samples should get higher weights, but not in an extreme way.\n",
        "\n",
        "A higher beta (like 0.9999) makes the correction more aggressive, meaning rare classes get boosted more strongly.\n",
        "\n",
        "After computing, the weights are normalized so they sum up to the number of classes.\n",
        "\n",
        "Use case: balances training by giving rare classes more importance without exploding values."
      ],
      "metadata": {
        "id": "zZso9s-Nq90m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_effective_weights_v2(class_counts, beta=0.9999):\n",
        "    \"\"\"More aggressive effective number (higher beta = less correction)\"\"\"\n",
        "    effective_num = 1.0 - np.power(beta, class_counts)\n",
        "    weights = (1.0 - beta) / effective_num\n",
        "    weights = weights / weights.sum() * len(weights)\n",
        "    return weights"
      ],
      "metadata": {
        "id": "CpdyXEdXooDD"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function computes inverse frequency weights: classes with fewer samples get larger weights.\n",
        "\n",
        "To avoid extreme values (like hundreds for very rare classes), the weights are capped at a maximum (cap=8.0).\n",
        "\n",
        "It also ensures weights don’t go below 0.5, so majority classes still retain some influence.\n",
        "\n",
        "Use case: a simpler, more controlled way to handle imbalance compared to effective number weighting."
      ],
      "metadata": {
        "id": "mj2zwErOrX39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_inverse_freq_capped(class_counts, cap=8.0):\n",
        "    \"\"\"Capped inverse frequency\"\"\"\n",
        "    total = class_counts.sum()\n",
        "    weights = total / (len(class_counts) * class_counts)\n",
        "    weights = np.clip(weights, 0.5, cap)\n",
        "    return weights"
      ],
      "metadata": {
        "id": "Ec8gL9WgrXQd"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. CONFIGURATIONS TO TEST\n",
        "\n",
        "This list defines different experimental setups for training with Focal Loss. Each dictionary represents one configuration, with parameters that control how the loss function handles class imbalance:\n",
        "\n",
        "- Gamma → controls how strongly the loss focuses on hard examples.\n",
        "- Beta → used in the effective number of samples weighting method.\n",
        "- Cap → used in the capped inverse frequency method."
      ],
      "metadata": {
        "id": "idwADN_qrqPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configs_to_test = [\n",
        "    {'name': 'Gamma_1.5_Beta_0.999', 'gamma': 1.5, 'beta': 0.999, 'cap': None},\n",
        "    {'name': 'Gamma_1.8_Beta_0.999', 'gamma': 1.8, 'beta': 0.999, 'cap': None},\n",
        "    {'name': 'Gamma_2.0_Beta_0.999', 'gamma': 2.0, 'beta': 0.999, 'cap': None},\n",
        "    {'name': 'Gamma_1.5_Cap_8', 'gamma': 1.5, 'beta': None, 'cap': 8.0},\n",
        "    {'name': 'Gamma_2.0_Cap_6', 'gamma': 2.0, 'beta': None, 'cap': 6.0},\n",
        "]"
      ],
      "metadata": {
        "id": "MWxPybyBsMVi"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Training function\n",
        "This is a compact training loop with early stopping based on macro F1‑score. It’s designed to quickly test models without running for too many epochs."
      ],
      "metadata": {
        "id": "ZNLdLO8ysjuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "def quick_train(model, train_loader, val_loader, criterion, device,\n",
        "                num_epochs=30, lr=0.001):\n",
        "    \"\"\"Quick training with early stopping\"\"\"\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max',\n",
        "                                                      factor=0.5, patience=4)\n",
        "\n",
        "    best_f1 = 0.0\n",
        "    best_model = None\n",
        "    patience = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Train\n",
        "        model.train()\n",
        "        for X, y in train_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(X), y)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validate\n",
        "        model.eval()\n",
        "        preds, targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for X, y in val_loader:\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                _, pred = torch.max(model(X), 1)\n",
        "                preds.extend(pred.cpu().numpy())\n",
        "                targets.extend(y.cpu().numpy())\n",
        "\n",
        "        f1 = f1_score(targets, preds, average='macro')\n",
        "        scheduler.step(f1)\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_model = deepcopy(model.state_dict())\n",
        "            patience = 0\n",
        "        else:\n",
        "            patience += 1\n",
        "            if patience >= 10:\n",
        "                break\n",
        "\n",
        "    return best_model, best_f1\n"
      ],
      "metadata": {
        "id": "lFZSJBAJsi4B"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. MAIN GRID SEARCH LOOP\n",
        "\n",
        "This block runs a grid search over different Focal Loss configurations to see which setup gives the best performance.\n",
        "\n",
        "\n",
        "\n",
        "1. Loop through configs: Iterates over each configuration in configs_to_test, showing its parameters (gamma, beta, cap).\n",
        "2. Weight calculation\n",
        "3. Model creation: Builds a fresh SplendorMLP\n",
        "4. Loss setup: Initializes Focal Loss with the chosen weights and gamma value.\n",
        "5. Training: Runs quick_train on the oversampled training set, tracking the best validation F1.\n",
        "6. Testing: Loads the best model weights, evaluates on the test set, and collects predictions.\n",
        "7. Metrics: Computes macro F1 and accuracy, then stores results (including predictions and targets) in a list for later analysis.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bcGbNBoWtJf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"FOCAL LOSS FINE-TUNING - GRID SEARCH\")\n",
        "\n",
        "results = []\n",
        "\n",
        "for i, cfg in enumerate(configs_to_test):\n",
        "    print(f\"\\n[{i+1}/{len(configs_to_test)}] Testing: {cfg['name']}\")\n",
        "    print(f\"  Gamma: {cfg['gamma']}, Beta: {cfg['beta']}, Cap: {cfg['cap']}\")\n",
        "\n",
        "    # Calculate weights\n",
        "    if cfg['cap'] is None:\n",
        "        weights = get_effective_weights_v2(class_counts, beta=cfg['beta'])\n",
        "    else:\n",
        "        weights = get_inverse_freq_capped(class_counts, cap=cfg['cap'])\n",
        "\n",
        "    print(f\"  Weights: {weights.round(4)}\")\n",
        "\n",
        "    # Create fresh model\n",
        "    model = SplendorMLP(144, 128, 64, 4, 0.4).to(device)\n",
        "    criterion = FocalLoss(\n",
        "        alpha=torch.FloatTensor(weights).to(device),\n",
        "        gamma=cfg['gamma']\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    best_model, val_f1 = quick_train(\n",
        "        model, train_loader_oversampled, val_loader, criterion, device\n",
        "    )\n",
        "\n",
        "    # Test\n",
        "    model.load_state_dict(best_model)\n",
        "    model.eval()\n",
        "    test_preds, test_targets = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            _, pred = torch.max(model(X), 1)\n",
        "            test_preds.extend(pred.cpu().numpy())\n",
        "            test_targets.extend(y.cpu().numpy())\n",
        "\n",
        "    test_f1 = f1_score(test_targets, test_preds, average='macro')\n",
        "    test_acc = 100 * accuracy_score(test_targets, test_preds)\n",
        "\n",
        "    results.append({\n",
        "        'name': cfg['name'],\n",
        "        'gamma': cfg['gamma'],\n",
        "        'val_f1': val_f1,\n",
        "        'test_f1': test_f1,\n",
        "        'test_acc': test_acc,\n",
        "        'model': best_model,\n",
        "        'preds': test_preds,\n",
        "        'targets': test_targets\n",
        "    })\n",
        "\n",
        "    print(f\"  Val F1: {val_f1:.4f} | Test F1: {test_f1:.4f} | Test Acc: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7rMOHf-tJDj",
        "outputId": "180ce869-af66-433a-8f7f-c408a9ed3c9e"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOCAL LOSS FINE-TUNING - GRID SEARCH\n",
            "\n",
            "[1/5] Testing: Gamma_1.5_Beta_0.999\n",
            "  Gamma: 1.5, Beta: 0.999, Cap: None\n",
            "  Weights: [0.3231 3.0227 0.3311 0.3231]\n",
            "  Val F1: 0.4947 | Test F1: 0.5076 | Test Acc: 72.95%\n",
            "\n",
            "[2/5] Testing: Gamma_1.8_Beta_0.999\n",
            "  Gamma: 1.8, Beta: 0.999, Cap: None\n",
            "  Weights: [0.3231 3.0227 0.3311 0.3231]\n",
            "  Val F1: 0.4718 | Test F1: 0.4729 | Test Acc: 71.78%\n",
            "\n",
            "[3/5] Testing: Gamma_2.0_Beta_0.999\n",
            "  Gamma: 2.0, Beta: 0.999, Cap: None\n",
            "  Weights: [0.3231 3.0227 0.3311 0.3231]\n",
            "  Val F1: 0.4808 | Test F1: 0.4976 | Test Acc: 71.74%\n",
            "\n",
            "[4/5] Testing: Gamma_1.5_Cap_8\n",
            "  Gamma: 1.5, Beta: None, Cap: 8.0\n",
            "  Weights: [0.5    8.     8.     0.5496]\n",
            "  Val F1: 0.4269 | Test F1: 0.4343 | Test Acc: 60.20%\n",
            "\n",
            "[5/5] Testing: Gamma_2.0_Cap_6\n",
            "  Gamma: 2.0, Beta: None, Cap: 6.0\n",
            "  Weights: [0.5    6.     6.     0.5496]\n",
            "  Val F1: 0.4327 | Test F1: 0.4257 | Test Acc: 59.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Results Ranked by Test F1\n",
        "\n",
        "Leaderboard of the grid search experiments"
      ],
      "metadata": {
        "id": "Ik6fBDChvUkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESULTS RANKED BY TEST F1\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "sorted_results = sorted(results, key=lambda x: x['test_f1'], reverse=True)\n",
        "\n",
        "for rank, r in enumerate(sorted_results, 1):\n",
        "    print(f\"{rank}. {r['name']:<25} | Val F1: {r['val_f1']:.4f} | \"\n",
        "          f\"Test F1: {r['test_f1']:.4f} | Acc: {r['test_acc']:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h70qS3m7vdRB",
        "outputId": "5ab392ad-c35a-42cd-c274-5bbfaac8d2f5"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "RESULTS RANKED BY TEST F1\n",
            "================================================================================\n",
            "1. Gamma_1.5_Beta_0.999      | Val F1: 0.4947 | Test F1: 0.5076 | Acc: 72.95%\n",
            "2. Gamma_2.0_Beta_0.999      | Val F1: 0.4808 | Test F1: 0.4976 | Acc: 71.74%\n",
            "3. Gamma_1.8_Beta_0.999      | Val F1: 0.4718 | Test F1: 0.4729 | Acc: 71.78%\n",
            "4. Gamma_1.5_Cap_8           | Val F1: 0.4269 | Test F1: 0.4343 | Acc: 60.20%\n",
            "5. Gamma_2.0_Cap_6           | Val F1: 0.4327 | Test F1: 0.4257 | Acc: 59.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Best Model Evaluation\n",
        "\n",
        "Full diagnostic view of the best model’s performance and preserves it for reuse."
      ],
      "metadata": {
        "id": "5N4Nfr44xMdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best = sorted_results[0]\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"BEST: {best['name']} (Gamma={best['gamma']})\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "best_preds = np.array(best['preds'])\n",
        "best_targets = np.array(best['targets'])\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(\n",
        "    best_targets, best_preds,\n",
        "    target_names=label_encoder.classes_,\n",
        "    digits=4\n",
        "))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(best_targets, best_preds)\n",
        "print(f\"{'':>20}\", end='')\n",
        "for label in label_encoder.classes_:\n",
        "    print(f\"{label:>15}\", end='')\n",
        "print()\n",
        "for i, label in enumerate(label_encoder.classes_):\n",
        "    print(f\"{label:>20}\", end='')\n",
        "    for j in range(len(label_encoder.classes_)):\n",
        "        print(f\"{cm[i][j]:>15}\", end='')\n",
        "    print()\n",
        "\n",
        "print(\"\\nPrediction vs Actual:\")\n",
        "for i, label in enumerate(label_encoder.classes_):\n",
        "    actual = (best_targets == i).sum()\n",
        "    pred = (best_preds == i).sum()\n",
        "    ratio = pred / actual if actual > 0 else 0\n",
        "    print(f\"{label:>20} | Pred: {pred:>5} | Actual: {actual:>5} | Ratio: {ratio:.2f}x\")\n",
        "\n",
        "# Save best model\n",
        "torch.save(best['model'], 'best_finetuned_focal_model.pth')\n",
        "print(\"\\nBest model saved: best_finetuned_focal_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzLZ26BbxCyH",
        "outputId": "279c6727-8ceb-42c0-81ba-1655c93a1ad9"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "BEST: Gamma_1.5_Beta_0.999 (Gamma=1.5)\n",
            "================================================================================\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        build     0.7322    0.8533    0.7881     15824\n",
            "      reserve     0.2105    0.3333    0.2581        24\n",
            "take 2 tokens     0.2712    0.3442    0.3034       799\n",
            "take 3 tokens     0.7688    0.6113    0.6811     13889\n",
            "\n",
            "     accuracy                         0.7295     30536\n",
            "    macro avg     0.4957    0.5355    0.5076     30536\n",
            " weighted avg     0.7364    0.7295    0.7263     30536\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "                              build        reserve  take 2 tokens  take 3 tokens\n",
            "               build          13502              9             70           2243\n",
            "             reserve             16              8              0              0\n",
            "       take 2 tokens            214              0            275            310\n",
            "       take 3 tokens           4709             21            669           8490\n",
            "\n",
            "Prediction vs Actual:\n",
            "               build | Pred: 18441 | Actual: 15824 | Ratio: 1.17x\n",
            "             reserve | Pred:    38 | Actual:    24 | Ratio: 1.58x\n",
            "       take 2 tokens | Pred:  1014 | Actual:   799 | Ratio: 1.27x\n",
            "       take 3 tokens | Pred: 11043 | Actual: 13889 | Ratio: 0.80x\n",
            "\n",
            "Best model saved: best_finetuned_focal_model.pth\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}